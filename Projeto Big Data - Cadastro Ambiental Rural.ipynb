{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96816ed7-b08a-4ca3-abb9-f99880c3535d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Cadastro Ambiental Rural\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50ebfcf5-3970-46c5-a15d-52dac692c366",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import year\n",
    "\n",
    "import boto3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d3e5f13-b689-4b24-9e50-765975a25f86",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Camada Bronze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8359356-9293-4493-8e3d-6cd659c0733f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#####Extraindo dados da landing zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11c3efe3-516d-4a4a-89ab-58cdb9da121e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_path = \"s3://temasambientais/temas_ambientais.csv\"\n",
    "df_temas_ambientais = spark.read.csv(file_path, header=True, inferSchema=True,sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1810f471-0922-4955-bec2-a0fd53d4357a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#####Verificando os nomes das colunas e os tipos de dados de cada coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29f32f28-cd0d-465f-9988-c52e1d770d56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[3]: [('uf', 'string'),\n ('municipio', 'string'),\n ('codigo_ibge', 'int'),\n ('area_do_imovel', 'double'),\n ('registro_car', 'string'),\n ('situacao_cadastro', 'string'),\n ('condicao_cadastro', 'string'),\n ('area_liquida', 'double'),\n ('area_remanescente_vegetacao_nativa', 'double'),\n ('area_reserva_legal_proposta', 'double'),\n ('area_preservacao_permanente', 'double'),\n ('area_nao_classificada', 'double'),\n ('solicitacao_adesao_pra', 'string'),\n ('latitude', 'double'),\n ('longitude', 'double'),\n ('data_inscricao', 'timestamp'),\n ('data_alteracao_condicao_cadastro', 'timestamp'),\n ('area_rural_consolidada', 'double'),\n ('area_servidao_administrativa', 'double'),\n ('tipo_imovel_rural', 'string'),\n ('modulos_fiscais', 'double'),\n ('area_uso_restrito', 'double'),\n ('area_reserva_legal_averbada', 'double'),\n ('area_reserva_legal_aprovada_nao_averbada', 'double'),\n ('area_pousio', 'double'),\n ('data_ultima_retificacao', 'timestamp')]"
     ]
    }
   ],
   "source": [
    "df_temas_ambientais.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "950e4026-2d05-467f-a86a-fed064cac67a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[4]: ['uf',\n 'municipio',\n 'codigo_ibge',\n 'area_do_imovel',\n 'registro_car',\n 'situacao_cadastro',\n 'condicao_cadastro',\n 'area_liquida',\n 'area_remanescente_vegetacao_nativa',\n 'area_reserva_legal_proposta',\n 'area_preservacao_permanente',\n 'area_nao_classificada',\n 'solicitacao_adesao_pra',\n 'latitude',\n 'longitude',\n 'data_inscricao',\n 'data_alteracao_condicao_cadastro',\n 'area_rural_consolidada',\n 'area_servidao_administrativa',\n 'tipo_imovel_rural',\n 'modulos_fiscais',\n 'area_uso_restrito',\n 'area_reserva_legal_averbada',\n 'area_reserva_legal_aprovada_nao_averbada',\n 'area_pousio',\n 'data_ultima_retificacao']"
     ]
    }
   ],
   "source": [
    "df_temas_ambientais.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f81c7b2-7d05-4f04-801c-c407006ce232",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#####Verificando quais os dados presentes no arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16013164-d951-4f30-9cc6-75f937e580b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uf</th>\n",
       "      <th>municipio</th>\n",
       "      <th>codigo_ibge</th>\n",
       "      <th>area_do_imovel</th>\n",
       "      <th>registro_car</th>\n",
       "      <th>situacao_cadastro</th>\n",
       "      <th>condicao_cadastro</th>\n",
       "      <th>area_liquida</th>\n",
       "      <th>area_remanescente_vegetacao_nativa</th>\n",
       "      <th>area_reserva_legal_proposta</th>\n",
       "      <th>...</th>\n",
       "      <th>data_alteracao_condicao_cadastro</th>\n",
       "      <th>area_rural_consolidada</th>\n",
       "      <th>area_servidao_administrativa</th>\n",
       "      <th>tipo_imovel_rural</th>\n",
       "      <th>modulos_fiscais</th>\n",
       "      <th>area_uso_restrito</th>\n",
       "      <th>area_reserva_legal_averbada</th>\n",
       "      <th>area_reserva_legal_aprovada_nao_averbada</th>\n",
       "      <th>area_pousio</th>\n",
       "      <th>data_ultima_retificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GO</td>\n",
       "      <td>Nazário</td>\n",
       "      <td>5214408</td>\n",
       "      <td>119.6326</td>\n",
       "      <td>GO-5214408-3AEF2043582E40238C0F84A553686CA7</td>\n",
       "      <td>AT</td>\n",
       "      <td>Analisado com pendências, aguardando retificaç...</td>\n",
       "      <td>119.6326</td>\n",
       "      <td>6.432028</td>\n",
       "      <td>6.4320</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>112.301149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IRU</td>\n",
       "      <td>5.4378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-05-07 16:01:44.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC</td>\n",
       "      <td>Meleiro</td>\n",
       "      <td>4210803</td>\n",
       "      <td>7.5340</td>\n",
       "      <td>SC-4210803-BC127B0EC8DB49AC9D46D723286241A2</td>\n",
       "      <td>AT</td>\n",
       "      <td>Aguardando análise, não passível de revisão de...</td>\n",
       "      <td>7.5340</td>\n",
       "      <td>5.517854</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2.014452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.4186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-05-07 16:02:02.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GO</td>\n",
       "      <td>Nova Roma</td>\n",
       "      <td>5214903</td>\n",
       "      <td>19.4883</td>\n",
       "      <td>GO-5214903-7F58049BD79046E9A904CC81C5AC177A</td>\n",
       "      <td>PE</td>\n",
       "      <td>Analisado com pendências, aguardando retificaç...</td>\n",
       "      <td>19.3600</td>\n",
       "      <td>19.488263</td>\n",
       "      <td>3.8720</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.2784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-05-07 16:06:15.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GO</td>\n",
       "      <td>Santa Helena de Goiás</td>\n",
       "      <td>5219308</td>\n",
       "      <td>22.9340</td>\n",
       "      <td>GO-5219308-6478196E75CF4F65800ACA0758575820</td>\n",
       "      <td>PE</td>\n",
       "      <td>Analisado com pendências, aguardando retificação</td>\n",
       "      <td>22.8800</td>\n",
       "      <td>1.502150</td>\n",
       "      <td>1.5028</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>3.082890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IRU</td>\n",
       "      <td>1.1467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-05-07 17:49:36.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PR</td>\n",
       "      <td>Cornélio Procópio</td>\n",
       "      <td>4106407</td>\n",
       "      <td>10.9560</td>\n",
       "      <td>PR-4106407-0F06081500254BE3A479EE8EFFDD5319</td>\n",
       "      <td>AT</td>\n",
       "      <td>Em análise</td>\n",
       "      <td>10.9560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>10.794267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.6087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-05-07 17:52:55.333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uf</th>\n      <th>municipio</th>\n      <th>codigo_ibge</th>\n      <th>area_do_imovel</th>\n      <th>registro_car</th>\n      <th>situacao_cadastro</th>\n      <th>condicao_cadastro</th>\n      <th>area_liquida</th>\n      <th>area_remanescente_vegetacao_nativa</th>\n      <th>area_reserva_legal_proposta</th>\n      <th>...</th>\n      <th>data_alteracao_condicao_cadastro</th>\n      <th>area_rural_consolidada</th>\n      <th>area_servidao_administrativa</th>\n      <th>tipo_imovel_rural</th>\n      <th>modulos_fiscais</th>\n      <th>area_uso_restrito</th>\n      <th>area_reserva_legal_averbada</th>\n      <th>area_reserva_legal_aprovada_nao_averbada</th>\n      <th>area_pousio</th>\n      <th>data_ultima_retificacao</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GO</td>\n      <td>Nazário</td>\n      <td>5214408</td>\n      <td>119.6326</td>\n      <td>GO-5214408-3AEF2043582E40238C0F84A553686CA7</td>\n      <td>AT</td>\n      <td>Analisado com pendências, aguardando retificaç...</td>\n      <td>119.6326</td>\n      <td>6.432028</td>\n      <td>6.4320</td>\n      <td>...</td>\n      <td>NaT</td>\n      <td>112.301149</td>\n      <td>0.0</td>\n      <td>IRU</td>\n      <td>5.4378</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2014-05-07 16:01:44.305</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SC</td>\n      <td>Meleiro</td>\n      <td>4210803</td>\n      <td>7.5340</td>\n      <td>SC-4210803-BC127B0EC8DB49AC9D46D723286241A2</td>\n      <td>AT</td>\n      <td>Aguardando análise, não passível de revisão de...</td>\n      <td>7.5340</td>\n      <td>5.517854</td>\n      <td>0.0000</td>\n      <td>...</td>\n      <td>NaT</td>\n      <td>2.014452</td>\n      <td>0.0</td>\n      <td>IRU</td>\n      <td>0.4186</td>\n      <td>0.0</td>\n      <td>1.506</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2014-05-07 16:02:02.915</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GO</td>\n      <td>Nova Roma</td>\n      <td>5214903</td>\n      <td>19.4883</td>\n      <td>GO-5214903-7F58049BD79046E9A904CC81C5AC177A</td>\n      <td>PE</td>\n      <td>Analisado com pendências, aguardando retificaç...</td>\n      <td>19.3600</td>\n      <td>19.488263</td>\n      <td>3.8720</td>\n      <td>...</td>\n      <td>NaT</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>IRU</td>\n      <td>0.2784</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2014-05-07 16:06:15.777</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GO</td>\n      <td>Santa Helena de Goiás</td>\n      <td>5219308</td>\n      <td>22.9340</td>\n      <td>GO-5219308-6478196E75CF4F65800ACA0758575820</td>\n      <td>PE</td>\n      <td>Analisado com pendências, aguardando retificação</td>\n      <td>22.8800</td>\n      <td>1.502150</td>\n      <td>1.5028</td>\n      <td>...</td>\n      <td>NaT</td>\n      <td>3.082890</td>\n      <td>0.0</td>\n      <td>IRU</td>\n      <td>1.1467</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2014-05-07 17:49:36.938</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PR</td>\n      <td>Cornélio Procópio</td>\n      <td>4106407</td>\n      <td>10.9560</td>\n      <td>PR-4106407-0F06081500254BE3A479EE8EFFDD5319</td>\n      <td>AT</td>\n      <td>Em análise</td>\n      <td>10.9560</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n      <td>...</td>\n      <td>NaT</td>\n      <td>10.794267</td>\n      <td>0.0</td>\n      <td>IRU</td>\n      <td>0.6087</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2014-05-07 17:52:55.333</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 26 columns</p>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_temas_ambientais.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc8f21dc-37f2-428d-ac1d-8c274897ff14",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#####Persistindo os dados na camada bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3acea899-cb8f-45dd-8ecc-ea3309a22acb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE SCHEMA IF NOT EXISTS bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a2b0737-ec4f-4893-a6db-8313fac507f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_table(df, format_type, schema_name, table_name, location):\n",
    "    schema = \", \".join([f\"{field.name} {field.dataType.simpleString()}\" for field in df.schema.fields])\n",
    "\n",
    "    spark.sql(f'''CREATE TABLE IF NOT EXISTS {schema_name}.{table_name} ({schema})\n",
    "              USING {format_type}\n",
    "              LOCATION '{location}'\n",
    "              ''')\n",
    "\n",
    "    df.write.format(format_type) \\\n",
    "       .mode(\"overwrite\") \\\n",
    "       .save(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "948837c5-35d3-4342-9e10-544df6a8be12",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "create_table(df_temas_ambientais,'parquet','bronze','temas_ambientais_bronze', '/FileStore/bronze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2922453c-a4a5-4480-817d-2710cf73d742",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/bronze/_SUCCESS</td><td>_SUCCESS</td><td>0</td><td>1716253079000</td></tr><tr><td>dbfs:/FileStore/bronze/_committed_5879178511176830258</td><td>_committed_5879178511176830258</td><td>2028</td><td>1716253079000</td></tr><tr><td>dbfs:/FileStore/bronze/_started_5879178511176830258</td><td>_started_5879178511176830258</td><td>0</td><td>1716252974000</td></tr><tr><td>dbfs:/FileStore/bronze/part-00000-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-304-1-c000.snappy.parquet</td><td>part-00000-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-304-1-c000.snappy.parquet</td><td>44897147</td><td>1716253071000</td></tr><tr><td>dbfs:/FileStore/bronze/part-00001-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-298-1-c000.snappy.parquet</td><td>part-00001-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-298-1-c000.snappy.parquet</td><td>44961539</td><td>1716253068000</td></tr><tr><td>dbfs:/FileStore/bronze/part-00002-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-290-1-c000.snappy.parquet</td><td>part-00002-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-290-1-c000.snappy.parquet</td><td>44818226</td><td>1716253018000</td></tr><tr><td>dbfs:/FileStore/bronze/part-00003-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-297-1-c000.snappy.parquet</td><td>part-00003-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-297-1-c000.snappy.parquet</td><td>45067859</td><td>1716253025000</td></tr><tr><td>dbfs:/FileStore/bronze/part-00004-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-302-1-c000.snappy.parquet</td><td>part-00004-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-302-1-c000.snappy.parquet</td><td>44844893</td><td>1716253072000</td></tr><tr><td>dbfs:/FileStore/bronze/part-00005-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-305-1-c000.snappy.parquet</td><td>part-00005-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-305-1-c000.snappy.parquet</td><td>44932070</td><td>1716253074000</td></tr><tr><td>dbfs:/FileStore/bronze/part-00006-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-306-1-c000.snappy.parquet</td><td>part-00006-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-306-1-c000.snappy.parquet</td><td>44945846</td><td>1716253079000</td></tr><tr><td>dbfs:/FileStore/bronze/part-00007-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-293-1-c000.snappy.parquet</td><td>part-00007-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-293-1-c000.snappy.parquet</td><td>44988588</td><td>1716253018000</td></tr><tr><td>dbfs:/FileStore/bronze/part-00008-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-295-1-c000.snappy.parquet</td><td>part-00008-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-295-1-c000.snappy.parquet</td><td>45001013</td><td>1716253018000</td></tr><tr><td>dbfs:/FileStore/bronze/part-00009-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-289-1-c000.snappy.parquet</td><td>part-00009-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-289-1-c000.snappy.parquet</td><td>45045811</td><td>1716253020000</td></tr><tr><td>dbfs:/FileStore/bronze/part-00010-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-301-1-c000.snappy.parquet</td><td>part-00010-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-301-1-c000.snappy.parquet</td><td>45037803</td><td>1716253073000</td></tr><tr><td>dbfs:/FileStore/bronze/part-00011-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-294-1-c000.snappy.parquet</td><td>part-00011-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-294-1-c000.snappy.parquet</td><td>44960567</td><td>1716253015000</td></tr><tr><td>dbfs:/FileStore/bronze/part-00012-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-300-1-c000.snappy.parquet</td><td>part-00012-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-300-1-c000.snappy.parquet</td><td>44907493</td><td>1716253062000</td></tr><tr><td>dbfs:/FileStore/bronze/part-00013-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-292-1-c000.snappy.parquet</td><td>part-00013-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-292-1-c000.snappy.parquet</td><td>45009689</td><td>1716253019000</td></tr><tr><td>dbfs:/FileStore/bronze/part-00014-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-296-1-c000.snappy.parquet</td><td>part-00014-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-296-1-c000.snappy.parquet</td><td>45066278</td><td>1716253008000</td></tr><tr><td>dbfs:/FileStore/bronze/part-00015-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-303-1-c000.snappy.parquet</td><td>part-00015-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-303-1-c000.snappy.parquet</td><td>44943901</td><td>1716253073000</td></tr><tr><td>dbfs:/FileStore/bronze/part-00016-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-291-1-c000.snappy.parquet</td><td>part-00016-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-291-1-c000.snappy.parquet</td><td>44988227</td><td>1716253018000</td></tr><tr><td>dbfs:/FileStore/bronze/part-00017-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-299-1-c000.snappy.parquet</td><td>part-00017-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-299-1-c000.snappy.parquet</td><td>44924279</td><td>1716253072000</td></tr><tr><td>dbfs:/FileStore/bronze/part-00018-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-307-1-c000.snappy.parquet</td><td>part-00018-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-307-1-c000.snappy.parquet</td><td>8513706</td><td>1716253076000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/FileStore/bronze/_SUCCESS",
         "_SUCCESS",
         0,
         1716253079000
        ],
        [
         "dbfs:/FileStore/bronze/_committed_5879178511176830258",
         "_committed_5879178511176830258",
         2028,
         1716253079000
        ],
        [
         "dbfs:/FileStore/bronze/_started_5879178511176830258",
         "_started_5879178511176830258",
         0,
         1716252974000
        ],
        [
         "dbfs:/FileStore/bronze/part-00000-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-304-1-c000.snappy.parquet",
         "part-00000-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-304-1-c000.snappy.parquet",
         44897147,
         1716253071000
        ],
        [
         "dbfs:/FileStore/bronze/part-00001-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-298-1-c000.snappy.parquet",
         "part-00001-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-298-1-c000.snappy.parquet",
         44961539,
         1716253068000
        ],
        [
         "dbfs:/FileStore/bronze/part-00002-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-290-1-c000.snappy.parquet",
         "part-00002-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-290-1-c000.snappy.parquet",
         44818226,
         1716253018000
        ],
        [
         "dbfs:/FileStore/bronze/part-00003-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-297-1-c000.snappy.parquet",
         "part-00003-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-297-1-c000.snappy.parquet",
         45067859,
         1716253025000
        ],
        [
         "dbfs:/FileStore/bronze/part-00004-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-302-1-c000.snappy.parquet",
         "part-00004-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-302-1-c000.snappy.parquet",
         44844893,
         1716253072000
        ],
        [
         "dbfs:/FileStore/bronze/part-00005-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-305-1-c000.snappy.parquet",
         "part-00005-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-305-1-c000.snappy.parquet",
         44932070,
         1716253074000
        ],
        [
         "dbfs:/FileStore/bronze/part-00006-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-306-1-c000.snappy.parquet",
         "part-00006-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-306-1-c000.snappy.parquet",
         44945846,
         1716253079000
        ],
        [
         "dbfs:/FileStore/bronze/part-00007-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-293-1-c000.snappy.parquet",
         "part-00007-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-293-1-c000.snappy.parquet",
         44988588,
         1716253018000
        ],
        [
         "dbfs:/FileStore/bronze/part-00008-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-295-1-c000.snappy.parquet",
         "part-00008-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-295-1-c000.snappy.parquet",
         45001013,
         1716253018000
        ],
        [
         "dbfs:/FileStore/bronze/part-00009-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-289-1-c000.snappy.parquet",
         "part-00009-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-289-1-c000.snappy.parquet",
         45045811,
         1716253020000
        ],
        [
         "dbfs:/FileStore/bronze/part-00010-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-301-1-c000.snappy.parquet",
         "part-00010-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-301-1-c000.snappy.parquet",
         45037803,
         1716253073000
        ],
        [
         "dbfs:/FileStore/bronze/part-00011-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-294-1-c000.snappy.parquet",
         "part-00011-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-294-1-c000.snappy.parquet",
         44960567,
         1716253015000
        ],
        [
         "dbfs:/FileStore/bronze/part-00012-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-300-1-c000.snappy.parquet",
         "part-00012-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-300-1-c000.snappy.parquet",
         44907493,
         1716253062000
        ],
        [
         "dbfs:/FileStore/bronze/part-00013-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-292-1-c000.snappy.parquet",
         "part-00013-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-292-1-c000.snappy.parquet",
         45009689,
         1716253019000
        ],
        [
         "dbfs:/FileStore/bronze/part-00014-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-296-1-c000.snappy.parquet",
         "part-00014-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-296-1-c000.snappy.parquet",
         45066278,
         1716253008000
        ],
        [
         "dbfs:/FileStore/bronze/part-00015-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-303-1-c000.snappy.parquet",
         "part-00015-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-303-1-c000.snappy.parquet",
         44943901,
         1716253073000
        ],
        [
         "dbfs:/FileStore/bronze/part-00016-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-291-1-c000.snappy.parquet",
         "part-00016-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-291-1-c000.snappy.parquet",
         44988227,
         1716253018000
        ],
        [
         "dbfs:/FileStore/bronze/part-00017-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-299-1-c000.snappy.parquet",
         "part-00017-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-299-1-c000.snappy.parquet",
         44924279,
         1716253072000
        ],
        [
         "dbfs:/FileStore/bronze/part-00018-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-307-1-c000.snappy.parquet",
         "part-00018-tid-5879178511176830258-67789624-7e2f-409b-86cb-258c76da8efd-307-1-c000.snappy.parquet",
         8513706,
         1716253076000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls /FileStore/bronze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc8d9213-0375-4dc9-a8bd-f390c07f84c9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Camada Silver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d46f68c4-f9ee-4935-aff1-894294ea9c97",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#####Carregando dados da camada bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5c4ab43-9210-4ebf-aeac-098932682c42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_table(schema_name, table_name):\n",
    "    full_table_name = f\"{schema_name}.{table_name}\"\n",
    "    df = spark.read.table(full_table_name)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3366b2d5-683d-4d3a-9d92-0949e5520c85",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[46]: [Row(uf='GO', municipio='Caiapônia', codigo_ibge=5204409, area_do_imovel=197.5993, registro_car='GO-5204409-79418BE625514399A28DC302DC17F013', situacao_cadastro='PE', condicao_cadastro='Analisado com pendências, aguardando retificação e/ou apresentação de documentos', area_liquida=197.2709, area_remanescente_vegetacao_nativa=197.599297358608, area_reserva_legal_proposta=39.5022, area_preservacao_permanente=83.6170568057138, area_nao_classificada=0.0, solicitacao_adesao_pra='Nao', latitude=-17.1671264858525, longitude=-51.4378006049413, data_inscricao=datetime.datetime(2014, 5, 11, 11, 16, 43, 969000), area_rural_consolidada=0.0, area_servidao_administrativa=0.0, tipo_imovel_rural='IRU', area_uso_restrito=0.0, area_pousio=0.0, data_ultima_retificacao=datetime.datetime(2014, 5, 11, 11, 16, 43, 969000), ano_inscricao=2014),\n Row(uf='GO', municipio='Santa Isabel', codigo_ibge=5219357, area_do_imovel=11.0505, registro_car='GO-5219357-7E2B0D59151D4A61ACF787E6CDB3F49B', situacao_cadastro='PE', condicao_cadastro='Analisado com pendências, aguardando retificação e/ou apresentação de documentos', area_liquida=11.0498, area_remanescente_vegetacao_nativa=3.98942374611944, area_reserva_legal_proposta=2.2087, area_preservacao_permanente=0.246375236566429, area_nao_classificada=0.277322398508179, solicitacao_adesao_pra='Nao', latitude=-15.373476443562, longitude=-49.3879966275568, data_inscricao=datetime.datetime(2014, 5, 19, 8, 57, 32, 380000), area_rural_consolidada=6.74891661980934, area_servidao_administrativa=0.0, tipo_imovel_rural='IRU', area_uso_restrito=0.0, area_pousio=0.0, data_ultima_retificacao=datetime.datetime(2014, 5, 19, 8, 57, 32, 380000), ano_inscricao=2014),\n Row(uf='MG', municipio='Santana do Manhuaçu', codigo_ibge=3158904, area_do_imovel=65.75, registro_car='MG-3158904-E4A1B494C2A34F9597676DD16774E75D', situacao_cadastro='AT', condicao_cadastro='Aguardando análise, não passível de revisão de dados', area_liquida=65.75, area_remanescente_vegetacao_nativa=25.33, area_reserva_legal_proposta=25.33, area_preservacao_permanente=3.24, area_nao_classificada=12.2211066470839, solicitacao_adesao_pra='Nao', latitude=-20.054759210073, longitude=-41.9691048394935, data_inscricao=datetime.datetime(2014, 5, 22, 9, 1, 17, 577000), area_rural_consolidada=40.4, area_servidao_administrativa=0.0, tipo_imovel_rural='IRU', area_uso_restrito=0.0, area_pousio=0.0, data_ultima_retificacao=datetime.datetime(2014, 5, 22, 9, 1, 17, 577000), ano_inscricao=2014),\n Row(uf='MG', municipio='Passos', codigo_ibge=3147907, area_do_imovel=66.5, registro_car='MG-3147907-9773480ED1EA4894A24A0B8301678AB5', situacao_cadastro='AT', condicao_cadastro='Aguardando análise, não passível de revisão de dados', area_liquida=66.5, area_remanescente_vegetacao_nativa=18.15, area_reserva_legal_proposta=18.15, area_preservacao_permanente=4.62, area_nao_classificada=56.6827943940219, solicitacao_adesao_pra='Nao', latitude=-20.9111773823043, longitude=-46.5688288298802, data_inscricao=datetime.datetime(2014, 5, 29, 9, 4, 26, 237000), area_rural_consolidada=44.81, area_servidao_administrativa=0.0, tipo_imovel_rural='IRU', area_uso_restrito=0.0, area_pousio=0.0, data_ultima_retificacao=datetime.datetime(2014, 5, 29, 9, 4, 26, 237000), ano_inscricao=2014),\n Row(uf='GO', municipio='Vila Propício', codigo_ibge=5222302, area_do_imovel=3.63, registro_car='GO-5222302-004E3C4E538041DAB06D53BD5C798C98', situacao_cadastro='AT', condicao_cadastro='Analisado com pendências, aguardando retificação', area_liquida=3.4234, area_remanescente_vegetacao_nativa=1.11916652233531, area_reserva_legal_proposta=0.6845, area_preservacao_permanente=0.704898862048658, area_nao_classificada=0.0, solicitacao_adesao_pra='Nao', latitude=-15.3501290318507, longitude=-49.0347373819904, data_inscricao=datetime.datetime(2014, 5, 29, 13, 24, 33, 472000), area_rural_consolidada=2.24500190472764, area_servidao_administrativa=0.2077, tipo_imovel_rural='IRU', area_uso_restrito=0.0, area_pousio=0.0, data_ultima_retificacao=datetime.datetime(2014, 5, 29, 13, 24, 33, 472000), ano_inscricao=2014)]"
     ]
    }
   ],
   "source": [
    "df_temas_ambientais = load_table('bronze', 'temas_ambientais_bronze')\n",
    "\n",
    "df_temas_ambientais.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be8cb69c-9240-4020-9d48-b6d120843e53",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uf</th>\n",
       "      <th>municipio</th>\n",
       "      <th>codigo_ibge</th>\n",
       "      <th>area_do_imovel</th>\n",
       "      <th>registro_car</th>\n",
       "      <th>situacao_cadastro</th>\n",
       "      <th>condicao_cadastro</th>\n",
       "      <th>area_liquida</th>\n",
       "      <th>area_remanescente_vegetacao_nativa</th>\n",
       "      <th>area_reserva_legal_proposta</th>\n",
       "      <th>...</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>data_inscricao</th>\n",
       "      <th>area_rural_consolidada</th>\n",
       "      <th>area_servidao_administrativa</th>\n",
       "      <th>tipo_imovel_rural</th>\n",
       "      <th>area_uso_restrito</th>\n",
       "      <th>area_pousio</th>\n",
       "      <th>data_ultima_retificacao</th>\n",
       "      <th>ano_inscricao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GO</td>\n",
       "      <td>Caiapônia</td>\n",
       "      <td>5204409</td>\n",
       "      <td>197.5993</td>\n",
       "      <td>GO-5204409-79418BE625514399A28DC302DC17F013</td>\n",
       "      <td>PE</td>\n",
       "      <td>Analisado com pendências, aguardando retificaç...</td>\n",
       "      <td>197.2709</td>\n",
       "      <td>197.599297</td>\n",
       "      <td>39.5022</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.167126</td>\n",
       "      <td>-51.437801</td>\n",
       "      <td>2014-05-11 11:16:43.969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-05-11 11:16:43.969</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GO</td>\n",
       "      <td>Santa Isabel</td>\n",
       "      <td>5219357</td>\n",
       "      <td>11.0505</td>\n",
       "      <td>GO-5219357-7E2B0D59151D4A61ACF787E6CDB3F49B</td>\n",
       "      <td>PE</td>\n",
       "      <td>Analisado com pendências, aguardando retificaç...</td>\n",
       "      <td>11.0498</td>\n",
       "      <td>3.989424</td>\n",
       "      <td>2.2087</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.373476</td>\n",
       "      <td>-49.387997</td>\n",
       "      <td>2014-05-19 08:57:32.380</td>\n",
       "      <td>6.748917</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-05-19 08:57:32.380</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MG</td>\n",
       "      <td>Santana do Manhuaçu</td>\n",
       "      <td>3158904</td>\n",
       "      <td>65.7500</td>\n",
       "      <td>MG-3158904-E4A1B494C2A34F9597676DD16774E75D</td>\n",
       "      <td>AT</td>\n",
       "      <td>Aguardando análise, não passível de revisão de...</td>\n",
       "      <td>65.7500</td>\n",
       "      <td>25.330000</td>\n",
       "      <td>25.3300</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.054759</td>\n",
       "      <td>-41.969105</td>\n",
       "      <td>2014-05-22 09:01:17.577</td>\n",
       "      <td>40.400000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-05-22 09:01:17.577</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MG</td>\n",
       "      <td>Passos</td>\n",
       "      <td>3147907</td>\n",
       "      <td>66.5000</td>\n",
       "      <td>MG-3147907-9773480ED1EA4894A24A0B8301678AB5</td>\n",
       "      <td>AT</td>\n",
       "      <td>Aguardando análise, não passível de revisão de...</td>\n",
       "      <td>66.5000</td>\n",
       "      <td>18.150000</td>\n",
       "      <td>18.1500</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.911177</td>\n",
       "      <td>-46.568829</td>\n",
       "      <td>2014-05-29 09:04:26.237</td>\n",
       "      <td>44.810000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-05-29 09:04:26.237</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GO</td>\n",
       "      <td>Vila Propício</td>\n",
       "      <td>5222302</td>\n",
       "      <td>3.6300</td>\n",
       "      <td>GO-5222302-004E3C4E538041DAB06D53BD5C798C98</td>\n",
       "      <td>AT</td>\n",
       "      <td>Analisado com pendências, aguardando retificação</td>\n",
       "      <td>3.4234</td>\n",
       "      <td>1.119167</td>\n",
       "      <td>0.6845</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.350129</td>\n",
       "      <td>-49.034737</td>\n",
       "      <td>2014-05-29 13:24:33.472</td>\n",
       "      <td>2.245002</td>\n",
       "      <td>0.2077</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-05-29 13:24:33.472</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uf</th>\n      <th>municipio</th>\n      <th>codigo_ibge</th>\n      <th>area_do_imovel</th>\n      <th>registro_car</th>\n      <th>situacao_cadastro</th>\n      <th>condicao_cadastro</th>\n      <th>area_liquida</th>\n      <th>area_remanescente_vegetacao_nativa</th>\n      <th>area_reserva_legal_proposta</th>\n      <th>...</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>data_inscricao</th>\n      <th>area_rural_consolidada</th>\n      <th>area_servidao_administrativa</th>\n      <th>tipo_imovel_rural</th>\n      <th>area_uso_restrito</th>\n      <th>area_pousio</th>\n      <th>data_ultima_retificacao</th>\n      <th>ano_inscricao</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GO</td>\n      <td>Caiapônia</td>\n      <td>5204409</td>\n      <td>197.5993</td>\n      <td>GO-5204409-79418BE625514399A28DC302DC17F013</td>\n      <td>PE</td>\n      <td>Analisado com pendências, aguardando retificaç...</td>\n      <td>197.2709</td>\n      <td>197.599297</td>\n      <td>39.5022</td>\n      <td>...</td>\n      <td>-17.167126</td>\n      <td>-51.437801</td>\n      <td>2014-05-11 11:16:43.969</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n      <td>IRU</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2014-05-11 11:16:43.969</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GO</td>\n      <td>Santa Isabel</td>\n      <td>5219357</td>\n      <td>11.0505</td>\n      <td>GO-5219357-7E2B0D59151D4A61ACF787E6CDB3F49B</td>\n      <td>PE</td>\n      <td>Analisado com pendências, aguardando retificaç...</td>\n      <td>11.0498</td>\n      <td>3.989424</td>\n      <td>2.2087</td>\n      <td>...</td>\n      <td>-15.373476</td>\n      <td>-49.387997</td>\n      <td>2014-05-19 08:57:32.380</td>\n      <td>6.748917</td>\n      <td>0.0000</td>\n      <td>IRU</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2014-05-19 08:57:32.380</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MG</td>\n      <td>Santana do Manhuaçu</td>\n      <td>3158904</td>\n      <td>65.7500</td>\n      <td>MG-3158904-E4A1B494C2A34F9597676DD16774E75D</td>\n      <td>AT</td>\n      <td>Aguardando análise, não passível de revisão de...</td>\n      <td>65.7500</td>\n      <td>25.330000</td>\n      <td>25.3300</td>\n      <td>...</td>\n      <td>-20.054759</td>\n      <td>-41.969105</td>\n      <td>2014-05-22 09:01:17.577</td>\n      <td>40.400000</td>\n      <td>0.0000</td>\n      <td>IRU</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2014-05-22 09:01:17.577</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MG</td>\n      <td>Passos</td>\n      <td>3147907</td>\n      <td>66.5000</td>\n      <td>MG-3147907-9773480ED1EA4894A24A0B8301678AB5</td>\n      <td>AT</td>\n      <td>Aguardando análise, não passível de revisão de...</td>\n      <td>66.5000</td>\n      <td>18.150000</td>\n      <td>18.1500</td>\n      <td>...</td>\n      <td>-20.911177</td>\n      <td>-46.568829</td>\n      <td>2014-05-29 09:04:26.237</td>\n      <td>44.810000</td>\n      <td>0.0000</td>\n      <td>IRU</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2014-05-29 09:04:26.237</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GO</td>\n      <td>Vila Propício</td>\n      <td>5222302</td>\n      <td>3.6300</td>\n      <td>GO-5222302-004E3C4E538041DAB06D53BD5C798C98</td>\n      <td>AT</td>\n      <td>Analisado com pendências, aguardando retificação</td>\n      <td>3.4234</td>\n      <td>1.119167</td>\n      <td>0.6845</td>\n      <td>...</td>\n      <td>-15.350129</td>\n      <td>-49.034737</td>\n      <td>2014-05-29 13:24:33.472</td>\n      <td>2.245002</td>\n      <td>0.2077</td>\n      <td>IRU</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2014-05-29 13:24:33.472</td>\n      <td>2014</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 23 columns</p>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_temas_ambientais.limit(10).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12c7556d-40f5-45fd-b9b2-4581fc715af8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns_to_drop = ['data_alteracao_condicao_cadastro', 'modulos_fiscais','area_reserva_legal_averbada', 'area_reserva_legal_aprovada_nao_averbada']\n",
    "df_temas_ambientais = df_temas_ambientais.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55195447-efa1-4d1d-b538-8ab12fe9df7d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#####Tratamento Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "866238b5-6145-428c-8f7c-76be3684ff24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[9]: 6839104"
     ]
    }
   ],
   "source": [
    "df_temas_ambientais.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7589f13-a91e-4ee9-b4a3-16f25d5db51f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[10]: 6839100"
     ]
    }
   ],
   "source": [
    "df_temas_ambientais = df_temas_ambientais.drop_duplicates()\n",
    "df_temas_ambientais.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc410e47-779e-4108-82ba-d6b05f446da9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uf</th>\n",
       "      <th>municipio</th>\n",
       "      <th>codigo_ibge</th>\n",
       "      <th>area_do_imovel</th>\n",
       "      <th>registro_car</th>\n",
       "      <th>situacao_cadastro</th>\n",
       "      <th>condicao_cadastro</th>\n",
       "      <th>area_liquida</th>\n",
       "      <th>area_remanescente_vegetacao_nativa</th>\n",
       "      <th>area_reserva_legal_proposta</th>\n",
       "      <th>...</th>\n",
       "      <th>solicitacao_adesao_pra</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>data_inscricao</th>\n",
       "      <th>area_rural_consolidada</th>\n",
       "      <th>area_servidao_administrativa</th>\n",
       "      <th>tipo_imovel_rural</th>\n",
       "      <th>area_uso_restrito</th>\n",
       "      <th>area_pousio</th>\n",
       "      <th>data_ultima_retificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GO</td>\n",
       "      <td>Santa Bárbara de Goiás</td>\n",
       "      <td>5219100</td>\n",
       "      <td>6.9875</td>\n",
       "      <td>GO-5219100-9C2FDEFBB58B4695AA92FCD659EB0094</td>\n",
       "      <td>AT</td>\n",
       "      <td>Aguardando análise, não passível de revisão de...</td>\n",
       "      <td>6.9875</td>\n",
       "      <td>0.058005</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>...</td>\n",
       "      <td>Nao</td>\n",
       "      <td>-16.574055</td>\n",
       "      <td>-49.673627</td>\n",
       "      <td>NaT</td>\n",
       "      <td>6.387876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-12-15 10:40:01.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PR</td>\n",
       "      <td>Maripá</td>\n",
       "      <td>4115358</td>\n",
       "      <td>5.2525</td>\n",
       "      <td>PR-4115358-BB7CCCF5EB0D48C9A7C6173942766F9C</td>\n",
       "      <td>AT</td>\n",
       "      <td>Aguardando análise, não passível de revisão de...</td>\n",
       "      <td>5.2525</td>\n",
       "      <td>1.326165</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>Nao</td>\n",
       "      <td>-24.391595</td>\n",
       "      <td>-53.765329</td>\n",
       "      <td>NaT</td>\n",
       "      <td>3.674385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-12-15 13:51:01.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PE</td>\n",
       "      <td>Santa Filomena</td>\n",
       "      <td>2612554</td>\n",
       "      <td>16.4470</td>\n",
       "      <td>PE-2612554-E538440C0E884365A48AE0F70321FC6D</td>\n",
       "      <td>AT</td>\n",
       "      <td>Aguardando análise, não passível de revisão de...</td>\n",
       "      <td>16.4470</td>\n",
       "      <td>5.469457</td>\n",
       "      <td>3.4252</td>\n",
       "      <td>...</td>\n",
       "      <td>Sim</td>\n",
       "      <td>-8.228723</td>\n",
       "      <td>-40.661958</td>\n",
       "      <td>NaT</td>\n",
       "      <td>10.977518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-12-15 11:00:48.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PR</td>\n",
       "      <td>São Pedro do Iguaçu</td>\n",
       "      <td>4125753</td>\n",
       "      <td>4.4803</td>\n",
       "      <td>PR-4125753-49312E58E65B43D5B651A6A2D74F417E</td>\n",
       "      <td>AT</td>\n",
       "      <td>Aguardando análise, não passível de revisão de...</td>\n",
       "      <td>4.4803</td>\n",
       "      <td>1.037868</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>Nao</td>\n",
       "      <td>-24.958925</td>\n",
       "      <td>-53.700504</td>\n",
       "      <td>NaT</td>\n",
       "      <td>3.001480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-12-15 14:04:08.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PR</td>\n",
       "      <td>Guarapuava</td>\n",
       "      <td>4109401</td>\n",
       "      <td>20.3838</td>\n",
       "      <td>PR-4109401-0EA6A1EE0B0E474B95748969A0C42FA0</td>\n",
       "      <td>AT</td>\n",
       "      <td>Aguardando análise, não passível de revisão de...</td>\n",
       "      <td>20.3838</td>\n",
       "      <td>2.301779</td>\n",
       "      <td>2.3018</td>\n",
       "      <td>...</td>\n",
       "      <td>Sim</td>\n",
       "      <td>-25.464702</td>\n",
       "      <td>-51.745105</td>\n",
       "      <td>NaT</td>\n",
       "      <td>18.071428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-12-15 13:19:08.511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PR</td>\n",
       "      <td>Ubiratã</td>\n",
       "      <td>4128005</td>\n",
       "      <td>22.5041</td>\n",
       "      <td>PR-4128005-6AA3862805FE4379B73051E718E0CA9B</td>\n",
       "      <td>AT</td>\n",
       "      <td>Aguardando análise, não passível de revisão de...</td>\n",
       "      <td>22.5041</td>\n",
       "      <td>0.730043</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>...</td>\n",
       "      <td>Sim</td>\n",
       "      <td>-24.424462</td>\n",
       "      <td>-53.032777</td>\n",
       "      <td>NaT</td>\n",
       "      <td>21.633508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-12-15 11:54:32.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PR</td>\n",
       "      <td>Ampére</td>\n",
       "      <td>4101002</td>\n",
       "      <td>7.1003</td>\n",
       "      <td>PR-4101002-253E4A517ECF4C02B9963AFFBA72786A</td>\n",
       "      <td>AT</td>\n",
       "      <td>Aguardando análise, não passível de revisão de...</td>\n",
       "      <td>7.0368</td>\n",
       "      <td>0.760083</td>\n",
       "      <td>0.4921</td>\n",
       "      <td>...</td>\n",
       "      <td>Nao</td>\n",
       "      <td>-25.957922</td>\n",
       "      <td>-53.529474</td>\n",
       "      <td>NaT</td>\n",
       "      <td>6.005326</td>\n",
       "      <td>0.063518</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-12-15 13:50:55.327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GO</td>\n",
       "      <td>Goianésia</td>\n",
       "      <td>5208608</td>\n",
       "      <td>401.4349</td>\n",
       "      <td>GO-5208608-213BBE0F2E944FF8962628517A6849F4</td>\n",
       "      <td>AT</td>\n",
       "      <td>Aguardando análise, não passível de revisão de...</td>\n",
       "      <td>401.4349</td>\n",
       "      <td>373.320726</td>\n",
       "      <td>80.2871</td>\n",
       "      <td>...</td>\n",
       "      <td>Nao</td>\n",
       "      <td>-15.561377</td>\n",
       "      <td>-49.193244</td>\n",
       "      <td>NaT</td>\n",
       "      <td>23.811648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-12-15 14:05:50.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SC</td>\n",
       "      <td>Concórdia</td>\n",
       "      <td>4204301</td>\n",
       "      <td>20.9761</td>\n",
       "      <td>SC-4204301-4D246918B6FB495EA22CF7A993C7EDAB</td>\n",
       "      <td>AT</td>\n",
       "      <td>Aguardando análise, não passível de revisão de...</td>\n",
       "      <td>20.3807</td>\n",
       "      <td>0.943300</td>\n",
       "      <td>0.9076</td>\n",
       "      <td>...</td>\n",
       "      <td>Nao</td>\n",
       "      <td>-27.238264</td>\n",
       "      <td>-52.110766</td>\n",
       "      <td>NaT</td>\n",
       "      <td>18.843823</td>\n",
       "      <td>0.595324</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-14 16:51:50.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GO</td>\n",
       "      <td>Bom Jesus de Goiás</td>\n",
       "      <td>5203500</td>\n",
       "      <td>280.0801</td>\n",
       "      <td>GO-5203500-7DF1ED8AD9E54427B14D66D2B0B3D711</td>\n",
       "      <td>AT</td>\n",
       "      <td>Aguardando análise, não passível de revisão de...</td>\n",
       "      <td>280.0801</td>\n",
       "      <td>38.851597</td>\n",
       "      <td>38.8463</td>\n",
       "      <td>...</td>\n",
       "      <td>Sim</td>\n",
       "      <td>-18.199628</td>\n",
       "      <td>-49.608582</td>\n",
       "      <td>NaT</td>\n",
       "      <td>239.063627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-26 08:14:09.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PR</td>\n",
       "      <td>Marechal Cândido Rondon</td>\n",
       "      <td>4114609</td>\n",
       "      <td>5.6600</td>\n",
       "      <td>PR-4114609-A4BB560897D04C65B76E3A4DFF75C9A8</td>\n",
       "      <td>AT</td>\n",
       "      <td>Aguardando análise, não passível de revisão de...</td>\n",
       "      <td>5.6600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6566</td>\n",
       "      <td>...</td>\n",
       "      <td>Sim</td>\n",
       "      <td>-24.512021</td>\n",
       "      <td>-54.020523</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4.700673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-07-17 10:47:42.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GO</td>\n",
       "      <td>Sanclerlândia</td>\n",
       "      <td>5219001</td>\n",
       "      <td>61.2385</td>\n",
       "      <td>GO-5219001-0C4734BAE199429F9405E31570BF178C</td>\n",
       "      <td>AT</td>\n",
       "      <td>Aguardando análise, não passível de revisão de...</td>\n",
       "      <td>61.2385</td>\n",
       "      <td>3.631209</td>\n",
       "      <td>3.6312</td>\n",
       "      <td>...</td>\n",
       "      <td>Sim</td>\n",
       "      <td>-16.162713</td>\n",
       "      <td>-50.333405</td>\n",
       "      <td>NaT</td>\n",
       "      <td>56.012635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>IRU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-06-20 14:02:15.445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 22 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uf</th>\n      <th>municipio</th>\n      <th>codigo_ibge</th>\n      <th>area_do_imovel</th>\n      <th>registro_car</th>\n      <th>situacao_cadastro</th>\n      <th>condicao_cadastro</th>\n      <th>area_liquida</th>\n      <th>area_remanescente_vegetacao_nativa</th>\n      <th>area_reserva_legal_proposta</th>\n      <th>...</th>\n      <th>solicitacao_adesao_pra</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>data_inscricao</th>\n      <th>area_rural_consolidada</th>\n      <th>area_servidao_administrativa</th>\n      <th>tipo_imovel_rural</th>\n      <th>area_uso_restrito</th>\n      <th>area_pousio</th>\n      <th>data_ultima_retificacao</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GO</td>\n      <td>Santa Bárbara de Goiás</td>\n      <td>5219100</td>\n      <td>6.9875</td>\n      <td>GO-5219100-9C2FDEFBB58B4695AA92FCD659EB0094</td>\n      <td>AT</td>\n      <td>Aguardando análise, não passível de revisão de...</td>\n      <td>6.9875</td>\n      <td>0.058005</td>\n      <td>0.0580</td>\n      <td>...</td>\n      <td>Nao</td>\n      <td>-16.574055</td>\n      <td>-49.673627</td>\n      <td>NaT</td>\n      <td>6.387876</td>\n      <td>0.000000</td>\n      <td>IRU</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2015-12-15 10:40:01.997</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>PR</td>\n      <td>Maripá</td>\n      <td>4115358</td>\n      <td>5.2525</td>\n      <td>PR-4115358-BB7CCCF5EB0D48C9A7C6173942766F9C</td>\n      <td>AT</td>\n      <td>Aguardando análise, não passível de revisão de...</td>\n      <td>5.2525</td>\n      <td>1.326165</td>\n      <td>0.0000</td>\n      <td>...</td>\n      <td>Nao</td>\n      <td>-24.391595</td>\n      <td>-53.765329</td>\n      <td>NaT</td>\n      <td>3.674385</td>\n      <td>0.000000</td>\n      <td>IRU</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2015-12-15 13:51:01.709</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PE</td>\n      <td>Santa Filomena</td>\n      <td>2612554</td>\n      <td>16.4470</td>\n      <td>PE-2612554-E538440C0E884365A48AE0F70321FC6D</td>\n      <td>AT</td>\n      <td>Aguardando análise, não passível de revisão de...</td>\n      <td>16.4470</td>\n      <td>5.469457</td>\n      <td>3.4252</td>\n      <td>...</td>\n      <td>Sim</td>\n      <td>-8.228723</td>\n      <td>-40.661958</td>\n      <td>NaT</td>\n      <td>10.977518</td>\n      <td>0.000000</td>\n      <td>IRU</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2015-12-15 11:00:48.270</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>PR</td>\n      <td>São Pedro do Iguaçu</td>\n      <td>4125753</td>\n      <td>4.4803</td>\n      <td>PR-4125753-49312E58E65B43D5B651A6A2D74F417E</td>\n      <td>AT</td>\n      <td>Aguardando análise, não passível de revisão de...</td>\n      <td>4.4803</td>\n      <td>1.037868</td>\n      <td>0.0000</td>\n      <td>...</td>\n      <td>Nao</td>\n      <td>-24.958925</td>\n      <td>-53.700504</td>\n      <td>NaT</td>\n      <td>3.001480</td>\n      <td>0.000000</td>\n      <td>IRU</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2015-12-15 14:04:08.693</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PR</td>\n      <td>Guarapuava</td>\n      <td>4109401</td>\n      <td>20.3838</td>\n      <td>PR-4109401-0EA6A1EE0B0E474B95748969A0C42FA0</td>\n      <td>AT</td>\n      <td>Aguardando análise, não passível de revisão de...</td>\n      <td>20.3838</td>\n      <td>2.301779</td>\n      <td>2.3018</td>\n      <td>...</td>\n      <td>Sim</td>\n      <td>-25.464702</td>\n      <td>-51.745105</td>\n      <td>NaT</td>\n      <td>18.071428</td>\n      <td>0.000000</td>\n      <td>IRU</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2015-12-15 13:19:08.511</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>PR</td>\n      <td>Ubiratã</td>\n      <td>4128005</td>\n      <td>22.5041</td>\n      <td>PR-4128005-6AA3862805FE4379B73051E718E0CA9B</td>\n      <td>AT</td>\n      <td>Aguardando análise, não passível de revisão de...</td>\n      <td>22.5041</td>\n      <td>0.730043</td>\n      <td>0.7300</td>\n      <td>...</td>\n      <td>Sim</td>\n      <td>-24.424462</td>\n      <td>-53.032777</td>\n      <td>NaT</td>\n      <td>21.633508</td>\n      <td>0.000000</td>\n      <td>IRU</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2015-12-15 11:54:32.284</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>PR</td>\n      <td>Ampére</td>\n      <td>4101002</td>\n      <td>7.1003</td>\n      <td>PR-4101002-253E4A517ECF4C02B9963AFFBA72786A</td>\n      <td>AT</td>\n      <td>Aguardando análise, não passível de revisão de...</td>\n      <td>7.0368</td>\n      <td>0.760083</td>\n      <td>0.4921</td>\n      <td>...</td>\n      <td>Nao</td>\n      <td>-25.957922</td>\n      <td>-53.529474</td>\n      <td>NaT</td>\n      <td>6.005326</td>\n      <td>0.063518</td>\n      <td>IRU</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2015-12-15 13:50:55.327</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>GO</td>\n      <td>Goianésia</td>\n      <td>5208608</td>\n      <td>401.4349</td>\n      <td>GO-5208608-213BBE0F2E944FF8962628517A6849F4</td>\n      <td>AT</td>\n      <td>Aguardando análise, não passível de revisão de...</td>\n      <td>401.4349</td>\n      <td>373.320726</td>\n      <td>80.2871</td>\n      <td>...</td>\n      <td>Nao</td>\n      <td>-15.561377</td>\n      <td>-49.193244</td>\n      <td>NaT</td>\n      <td>23.811648</td>\n      <td>0.000000</td>\n      <td>IRU</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2015-12-15 14:05:50.736</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>SC</td>\n      <td>Concórdia</td>\n      <td>4204301</td>\n      <td>20.9761</td>\n      <td>SC-4204301-4D246918B6FB495EA22CF7A993C7EDAB</td>\n      <td>AT</td>\n      <td>Aguardando análise, não passível de revisão de...</td>\n      <td>20.3807</td>\n      <td>0.943300</td>\n      <td>0.9076</td>\n      <td>...</td>\n      <td>Nao</td>\n      <td>-27.238264</td>\n      <td>-52.110766</td>\n      <td>NaT</td>\n      <td>18.843823</td>\n      <td>0.595324</td>\n      <td>IRU</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2016-04-14 16:51:50.885</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>GO</td>\n      <td>Bom Jesus de Goiás</td>\n      <td>5203500</td>\n      <td>280.0801</td>\n      <td>GO-5203500-7DF1ED8AD9E54427B14D66D2B0B3D711</td>\n      <td>AT</td>\n      <td>Aguardando análise, não passível de revisão de...</td>\n      <td>280.0801</td>\n      <td>38.851597</td>\n      <td>38.8463</td>\n      <td>...</td>\n      <td>Sim</td>\n      <td>-18.199628</td>\n      <td>-49.608582</td>\n      <td>NaT</td>\n      <td>239.063627</td>\n      <td>0.000000</td>\n      <td>IRU</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2016-04-26 08:14:09.734</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>PR</td>\n      <td>Marechal Cândido Rondon</td>\n      <td>4114609</td>\n      <td>5.6600</td>\n      <td>PR-4114609-A4BB560897D04C65B76E3A4DFF75C9A8</td>\n      <td>AT</td>\n      <td>Aguardando análise, não passível de revisão de...</td>\n      <td>5.6600</td>\n      <td>0.000000</td>\n      <td>0.6566</td>\n      <td>...</td>\n      <td>Sim</td>\n      <td>-24.512021</td>\n      <td>-54.020523</td>\n      <td>NaT</td>\n      <td>4.700673</td>\n      <td>0.000000</td>\n      <td>IRU</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-07-17 10:47:42.330</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>GO</td>\n      <td>Sanclerlândia</td>\n      <td>5219001</td>\n      <td>61.2385</td>\n      <td>GO-5219001-0C4734BAE199429F9405E31570BF178C</td>\n      <td>AT</td>\n      <td>Aguardando análise, não passível de revisão de...</td>\n      <td>61.2385</td>\n      <td>3.631209</td>\n      <td>3.6312</td>\n      <td>...</td>\n      <td>Sim</td>\n      <td>-16.162713</td>\n      <td>-50.333405</td>\n      <td>NaT</td>\n      <td>56.012635</td>\n      <td>0.000000</td>\n      <td>IRU</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2022-06-20 14:02:15.445</td>\n    </tr>\n  </tbody>\n</table>\n<p>12 rows × 22 columns</p>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_temas_ambientais.filter(col(\"data_inscricao\").isNull()).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b90d75e3-51b5-4e9f-9654-5942baa87376",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[12]: 6839100"
     ]
    }
   ],
   "source": [
    "df_temas_ambientais.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca8e080c-e979-4b88-aa75-a1d657b75eca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_temas_ambientais = df_temas_ambientais.where(df_temas_ambientais.data_inscricao.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f5f6e80-08cb-4cc8-b190-78902ab53555",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_temas_ambientais.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cca0065-c914-4e6f-a280-952b263dfdcd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#####Escrever os DFs em tabelas Delta Lake com um projeto de particionamento efetivo conforme o contexto empresarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b093046b-3ed0-446f-97cd-d0ff6bb86e41",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE SCHEMA IF NOT EXISTS silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "974848b1-4c1b-44ea-9216-96a24bbcb672",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_table_with_partition(df, format_type, partition_by, schema_name, table_name, location):\n",
    "    partition_clause = \", \".join(partition_by)\n",
    "\n",
    "    schema = \", \".join([f\"{field.name} {field.dataType.simpleString()}\" for field in df.schema.fields])\n",
    "\n",
    "    spark.sql(f'''CREATE TABLE IF NOT EXISTS {schema_name}.{table_name} ({schema})\n",
    "              USING {format_type}\n",
    "              PARTITIONED BY ({partition_clause})\n",
    "              LOCATION '{location}'\n",
    "              ''')\n",
    "\n",
    "    df.write.format(format_type) \\\n",
    "       .mode(\"overwrite\") \\\n",
    "       .partitionBy(partition_by) \\\n",
    "       .save(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd77a209-c1c8-4bba-a360-39f3eba2ee35",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls /FileStore/silver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25770759-8b3f-4207-a179-e04ad553a901",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Criada a coluna \"ano_inscricao\" a partir da data_inscricao para ser utilizado na partição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fad71b58-7374-4a09-bcf1-2a4e8554ae73",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_temas_ambientais = df_temas_ambientais.withColumn(\"ano_inscricao\", year(\"data_inscricao\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48cd7dda-f759-4a9e-9978-89af6a6c00c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "create_table_with_partition(df_temas_ambientais, 'DELTA', ['uf','ano_inscricao'], 'silver', 'temas_ambientais', '/FileStore/silver/temas_ambientais/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a0f5584-2be7-4120-b587-ab82207f027e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    " Tabela Delta Lake criadas na camada silver: \n",
    " 1. temas_ambientais, particionado por 'uf' e 'ano_inscricao'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e88efbf-8157-419d-a76a-995f687dd85d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Camada Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f2a9540-4592-42a9-8a08-86aa1c6e184e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE SCHEMA IF NOT EXISTS gold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1ba7d0d-b2b3-404c-a8e0-2b8ef17d699e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Tabela de \"Temas Ambientais\" por Região do BR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3f9cefe-6466-4b37-ac1c-44907ede1cb5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE TABLE IF NOT EXISTS gold.temas_ambientais_por_regiao AS\n",
    "SELECT *,\n",
    "  CASE \n",
    "    WHEN uf IN ('SP', 'RJ', 'MG', 'ES') THEN 'Sudeste'\n",
    "    WHEN uf IN ('PR', 'RS', 'SC') THEN 'Sul'\n",
    "    WHEN uf IN ('GO', 'MT', 'MS', 'DF') THEN 'Centro-Oeste'\n",
    "    WHEN uf IN ('AC', 'AP', 'AM', 'PA', 'RO', 'RR', 'TO') THEN 'Norte'\n",
    "    WHEN uf IN ('AL', 'BA', 'CE', 'MA', 'PB', 'PE', 'PI', 'RN', 'SE') THEN 'Nordeste'\n",
    "    ELSE 'Outra'\n",
    "  END AS regiao\n",
    "FROM silver.temas_ambientais;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd5dce76-9d5c-48fe-97cd-c799960415c3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Tabela de Propriedades com Área Remanescente de Vegetação Nativa por UF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df6e3199-49a0-493b-ac38-7101d344da17",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-641900871737069>:7\u001B[0m\n",
       "\u001B[1;32m      5\u001B[0m     display(df)\n",
       "\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
       "\u001B[0;32m----> 7\u001B[0m   _sqldf \u001B[38;5;241m=\u001B[39m \u001B[43m____databricks_percent_sql\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m      9\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m ____databricks_percent_sql\n",
       "\n",
       "File \u001B[0;32m<command-641900871737069>:4\u001B[0m, in \u001B[0;36m____databricks_percent_sql\u001B[0;34m()\u001B[0m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m____databricks_percent_sql\u001B[39m():\n",
       "\u001B[1;32m      3\u001B[0m   \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbase64\u001B[39;00m\n",
       "\u001B[0;32m----> 4\u001B[0m   df \u001B[38;5;241m=\u001B[39m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase64\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstandard_b64decode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mQ1JFQVRFIFRBQkxFIElGIE5PVCBFWElTVFMgZ29sZC5wcm9wcmllZGFkZXNfYXJlYV9uYXRpdmFfdWYgQVMKU0VMRUNUIHVmLCBDT1VOVCgqKSBBUyBudW1fcHJvcHJpZWRhZGVzX2FyZWFfbmF0aXZhCkZST00gc2lsdmVyLnRlbWFzX2FtYmllbnRhaXMKV0hFUkUgYXJlYV9yZW1hbmVzY2VudGVfdmVnZXRhY2FvX25hdGl2YSA+IDAKR1JPVVAgQlkgdWY=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m      5\u001B[0m   display(df)\n",
       "\u001B[1;32m      6\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/session.py:1387\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1385\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[1;32m   1386\u001B[0m     litArgs \u001B[38;5;241m=\u001B[39m {k: _to_java_column(lit(v)) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m (args \u001B[38;5;129;01mor\u001B[39;00m {})\u001B[38;5;241m.\u001B[39mitems()}\n",
       "\u001B[0;32m-> 1387\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43msqlQuery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlitArgs\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m)\n",
       "\u001B[1;32m   1388\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m   1389\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(kwargs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `silver`.`temas_ambientais` cannot be found. Verify the spelling and correctness of the schema and catalog.\n",
       "If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\n",
       "To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 3 pos 5;\n",
       "'CreateTableAsSelect TableSpec(Map(),None,Map(),None,None,None,false,Set(),None,None), true\n",
       ":- ResolvedIdentifier com.databricks.sql.managedcatalog.UnityCatalogV2Proxy@28ebc8b7, gold.propriedades_area_nativa_uf\n",
       "+- 'Aggregate ['uf], ['uf, count(1) AS num_propriedades_area_nativa#2908L]\n",
       "   +- 'Filter ('area_remanescente_vegetacao_nativa > 0)\n",
       "      +- 'UnresolvedRelation [silver, temas_ambientais], [], false\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\nFile \u001B[0;32m<command-641900871737069>:7\u001B[0m\n\u001B[1;32m      5\u001B[0m     display(df)\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n\u001B[0;32m----> 7\u001B[0m   _sqldf \u001B[38;5;241m=\u001B[39m \u001B[43m____databricks_percent_sql\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m      9\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m ____databricks_percent_sql\n\nFile \u001B[0;32m<command-641900871737069>:4\u001B[0m, in \u001B[0;36m____databricks_percent_sql\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m____databricks_percent_sql\u001B[39m():\n\u001B[1;32m      3\u001B[0m   \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbase64\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m   df \u001B[38;5;241m=\u001B[39m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase64\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstandard_b64decode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mQ1JFQVRFIFRBQkxFIElGIE5PVCBFWElTVFMgZ29sZC5wcm9wcmllZGFkZXNfYXJlYV9uYXRpdmFfdWYgQVMKU0VMRUNUIHVmLCBDT1VOVCgqKSBBUyBudW1fcHJvcHJpZWRhZGVzX2FyZWFfbmF0aXZhCkZST00gc2lsdmVyLnRlbWFzX2FtYmllbnRhaXMKV0hFUkUgYXJlYV9yZW1hbmVzY2VudGVfdmVnZXRhY2FvX25hdGl2YSA+IDAKR1JPVVAgQlkgdWY=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m   display(df)\n\u001B[1;32m      6\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m df\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/session.py:1387\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n\u001B[1;32m   1385\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1386\u001B[0m     litArgs \u001B[38;5;241m=\u001B[39m {k: _to_java_column(lit(v)) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m (args \u001B[38;5;129;01mor\u001B[39;00m {})\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[0;32m-> 1387\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43msqlQuery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlitArgs\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m   1388\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m   1389\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(kwargs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\n\u001B[0;31mAnalysisException\u001B[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `silver`.`temas_ambientais` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 3 pos 5;\n'CreateTableAsSelect TableSpec(Map(),None,Map(),None,None,None,false,Set(),None,None), true\n:- ResolvedIdentifier com.databricks.sql.managedcatalog.UnityCatalogV2Proxy@28ebc8b7, gold.propriedades_area_nativa_uf\n+- 'Aggregate ['uf], ['uf, count(1) AS num_propriedades_area_nativa#2908L]\n   +- 'Filter ('area_remanescente_vegetacao_nativa > 0)\n      +- 'UnresolvedRelation [silver, temas_ambientais], [], false\n",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: [TABLE_OR_VIEW_NOT_FOUND] The table or view `silver`.`temas_ambientais` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 3 pos 5;\n'CreateTableAsSelect TableSpec(Map(),None,Map(),None,None,None,false,Set(),None,None), true\n:- ResolvedIdentifier com.databricks.sql.managedcatalog.UnityCatalogV2Proxy@28ebc8b7, gold.propriedades_area_nativa_uf\n+- 'Aggregate ['uf], ['uf, count(1) AS num_propriedades_area_nativa#2908L]\n   +- 'Filter ('area_remanescente_vegetacao_nativa > 0)\n      +- 'UnresolvedRelation [silver, temas_ambientais], [], false\n",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE TABLE IF NOT EXISTS gold.propriedades_area_nativa_uf AS\n",
    "SELECT uf, COUNT(*) AS num_propriedades_area_nativa\n",
    "FROM silver.temas_ambientais\n",
    "WHERE area_remanescente_vegetacao_nativa > 0\n",
    "GROUP BY uf;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5c14d5e-0666-4bd3-93db-f1243328089a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls dbfs:/user/hive/warehouse/gold.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d4f4ddb-e641-4313-bfd9-9f17805c666d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Consultas Analíticas (Contexto Empresarial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73ef64e0-9094-42e6-8546-00369b44a279",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "1. Recupere a soma de área (em hectares) para todas as propriedades agrícolas que\n",
    "pertencem ao MS e MT. Ordene os resultados em ordem decrescente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f7c2630-b08b-4386-bfdf-56c47a30dd35",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2597619522200211>:7\u001B[0m\n",
       "\u001B[1;32m      5\u001B[0m     display(df)\n",
       "\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
       "\u001B[0;32m----> 7\u001B[0m   _sqldf \u001B[38;5;241m=\u001B[39m \u001B[43m____databricks_percent_sql\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m      9\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m ____databricks_percent_sql\n",
       "\n",
       "File \u001B[0;32m<command-2597619522200211>:4\u001B[0m, in \u001B[0;36m____databricks_percent_sql\u001B[0;34m()\u001B[0m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m____databricks_percent_sql\u001B[39m():\n",
       "\u001B[1;32m      3\u001B[0m   \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbase64\u001B[39;00m\n",
       "\u001B[0;32m----> 4\u001B[0m   df \u001B[38;5;241m=\u001B[39m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase64\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstandard_b64decode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mU0VMRUNUIHVmLCBTVU0oYXJlYV9kb19pbW92ZWwpIEFTIHNvbWFfYXJlYQpGUk9NIHNpbHZlci50ZW1hc19hbWJpZW50YWlzCldIRVJFIHVmIElOICgnTVMnLCAnTVQnKQpHUk9VUCBCWSB1ZgpPUkRFUiBCWSBzb21hX2FyZWEgREVTQw==\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m      5\u001B[0m   display(df)\n",
       "\u001B[1;32m      6\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/session.py:1387\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1385\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[1;32m   1386\u001B[0m     litArgs \u001B[38;5;241m=\u001B[39m {k: _to_java_column(lit(v)) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m (args \u001B[38;5;129;01mor\u001B[39;00m {})\u001B[38;5;241m.\u001B[39mitems()}\n",
       "\u001B[0;32m-> 1387\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43msqlQuery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlitArgs\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m)\n",
       "\u001B[1;32m   1388\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m   1389\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(kwargs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `silver`.`temas_ambientais` cannot be found. Verify the spelling and correctness of the schema and catalog.\n",
       "If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\n",
       "To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 2 pos 5;\n",
       "'Sort ['soma_area DESC NULLS LAST], true\n",
       "+- 'Aggregate ['uf], ['uf, 'SUM('area_do_imovel) AS soma_area#1627]\n",
       "   +- 'Filter 'uf IN (MS,MT)\n",
       "      +- 'UnresolvedRelation [silver, temas_ambientais], [], false\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\nFile \u001B[0;32m<command-2597619522200211>:7\u001B[0m\n\u001B[1;32m      5\u001B[0m     display(df)\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n\u001B[0;32m----> 7\u001B[0m   _sqldf \u001B[38;5;241m=\u001B[39m \u001B[43m____databricks_percent_sql\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m      9\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m ____databricks_percent_sql\n\nFile \u001B[0;32m<command-2597619522200211>:4\u001B[0m, in \u001B[0;36m____databricks_percent_sql\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m____databricks_percent_sql\u001B[39m():\n\u001B[1;32m      3\u001B[0m   \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbase64\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m   df \u001B[38;5;241m=\u001B[39m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase64\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstandard_b64decode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mU0VMRUNUIHVmLCBTVU0oYXJlYV9kb19pbW92ZWwpIEFTIHNvbWFfYXJlYQpGUk9NIHNpbHZlci50ZW1hc19hbWJpZW50YWlzCldIRVJFIHVmIElOICgnTVMnLCAnTVQnKQpHUk9VUCBCWSB1ZgpPUkRFUiBCWSBzb21hX2FyZWEgREVTQw==\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m   display(df)\n\u001B[1;32m      6\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m df\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/session.py:1387\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n\u001B[1;32m   1385\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1386\u001B[0m     litArgs \u001B[38;5;241m=\u001B[39m {k: _to_java_column(lit(v)) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m (args \u001B[38;5;129;01mor\u001B[39;00m {})\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[0;32m-> 1387\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43msqlQuery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlitArgs\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m   1388\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m   1389\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(kwargs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\n\u001B[0;31mAnalysisException\u001B[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `silver`.`temas_ambientais` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 2 pos 5;\n'Sort ['soma_area DESC NULLS LAST], true\n+- 'Aggregate ['uf], ['uf, 'SUM('area_do_imovel) AS soma_area#1627]\n   +- 'Filter 'uf IN (MS,MT)\n      +- 'UnresolvedRelation [silver, temas_ambientais], [], false\n",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: [TABLE_OR_VIEW_NOT_FOUND] The table or view `silver`.`temas_ambientais` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 2 pos 5;\n'Sort ['soma_area DESC NULLS LAST], true\n+- 'Aggregate ['uf], ['uf, 'SUM('area_do_imovel) AS soma_area#1627]\n   +- 'Filter 'uf IN (MS,MT)\n      +- 'UnresolvedRelation [silver, temas_ambientais], [], false\n",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT uf, SUM(area_do_imovel) AS soma_area\n",
    "FROM silver.temas_ambientais\n",
    "WHERE uf IN ('MS', 'MT')\n",
    "GROUP BY uf\n",
    "ORDER BY soma_area DESC;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16aeb971-adc0-494b-bd97-73c3d342d8c5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "2. Filtre todas as propriedades que pertencem a região sudeste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "247c0ade-e57f-44af-8a57-1352583268b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-641900871737074>:7\u001B[0m\n",
       "\u001B[1;32m      5\u001B[0m     display(df)\n",
       "\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
       "\u001B[0;32m----> 7\u001B[0m   _sqldf \u001B[38;5;241m=\u001B[39m \u001B[43m____databricks_percent_sql\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m      9\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m ____databricks_percent_sql\n",
       "\n",
       "File \u001B[0;32m<command-641900871737074>:4\u001B[0m, in \u001B[0;36m____databricks_percent_sql\u001B[0;34m()\u001B[0m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m____databricks_percent_sql\u001B[39m():\n",
       "\u001B[1;32m      3\u001B[0m   \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbase64\u001B[39;00m\n",
       "\u001B[0;32m----> 4\u001B[0m   df \u001B[38;5;241m=\u001B[39m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase64\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstandard_b64decode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mU0VMRUNUICoKRlJPTSBnb2xkLnRlbWFzX2FtYmllbnRhaXNfcG9yX3JlZ2lhbwpXSEVSRSByZWdpYW8gPSAnU3VkZXN0ZScKTElNSVQgMTA=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m      5\u001B[0m   display(df)\n",
       "\u001B[1;32m      6\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/session.py:1387\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1385\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[1;32m   1386\u001B[0m     litArgs \u001B[38;5;241m=\u001B[39m {k: _to_java_column(lit(v)) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m (args \u001B[38;5;129;01mor\u001B[39;00m {})\u001B[38;5;241m.\u001B[39mitems()}\n",
       "\u001B[0;32m-> 1387\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43msqlQuery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlitArgs\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m)\n",
       "\u001B[1;32m   1388\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m   1389\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(kwargs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `gold`.`temas_ambientais_por_regiao` cannot be found. Verify the spelling and correctness of the schema and catalog.\n",
       "If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\n",
       "To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 2 pos 5;\n",
       "'GlobalLimit 10\n",
       "+- 'LocalLimit 10\n",
       "   +- 'Project [*]\n",
       "      +- 'Filter ('regiao = Sudeste)\n",
       "         +- 'UnresolvedRelation [gold, temas_ambientais_por_regiao], [], false\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\nFile \u001B[0;32m<command-641900871737074>:7\u001B[0m\n\u001B[1;32m      5\u001B[0m     display(df)\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n\u001B[0;32m----> 7\u001B[0m   _sqldf \u001B[38;5;241m=\u001B[39m \u001B[43m____databricks_percent_sql\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m      9\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m ____databricks_percent_sql\n\nFile \u001B[0;32m<command-641900871737074>:4\u001B[0m, in \u001B[0;36m____databricks_percent_sql\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m____databricks_percent_sql\u001B[39m():\n\u001B[1;32m      3\u001B[0m   \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbase64\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m   df \u001B[38;5;241m=\u001B[39m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase64\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstandard_b64decode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mU0VMRUNUICoKRlJPTSBnb2xkLnRlbWFzX2FtYmllbnRhaXNfcG9yX3JlZ2lhbwpXSEVSRSByZWdpYW8gPSAnU3VkZXN0ZScKTElNSVQgMTA=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m   display(df)\n\u001B[1;32m      6\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m df\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/session.py:1387\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n\u001B[1;32m   1385\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1386\u001B[0m     litArgs \u001B[38;5;241m=\u001B[39m {k: _to_java_column(lit(v)) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m (args \u001B[38;5;129;01mor\u001B[39;00m {})\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[0;32m-> 1387\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43msqlQuery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlitArgs\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m   1388\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m   1389\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(kwargs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\n\u001B[0;31mAnalysisException\u001B[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `gold`.`temas_ambientais_por_regiao` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 2 pos 5;\n'GlobalLimit 10\n+- 'LocalLimit 10\n   +- 'Project [*]\n      +- 'Filter ('regiao = Sudeste)\n         +- 'UnresolvedRelation [gold, temas_ambientais_por_regiao], [], false\n",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: [TABLE_OR_VIEW_NOT_FOUND] The table or view `gold`.`temas_ambientais_por_regiao` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 2 pos 5;\n'GlobalLimit 10\n+- 'LocalLimit 10\n   +- 'Project [*]\n      +- 'Filter ('regiao = Sudeste)\n         +- 'UnresolvedRelation [gold, temas_ambientais_por_regiao], [], false\n",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM gold.temas_ambientais_por_regiao\n",
    "WHERE regiao = 'Sudeste'\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "078f74da-4067-48b4-94e5-f71a06fcc93c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "3. Calcule quantas propriedades foram cadastradas por ano. Apresente os resultados em\n",
    "ordem cronológica.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44f3c228-52a0-4fb6-a51d-a8f780e13f01",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-641900871737076>:7\u001B[0m\n",
       "\u001B[1;32m      5\u001B[0m     display(df)\n",
       "\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
       "\u001B[0;32m----> 7\u001B[0m   _sqldf \u001B[38;5;241m=\u001B[39m \u001B[43m____databricks_percent_sql\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m      9\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m ____databricks_percent_sql\n",
       "\n",
       "File \u001B[0;32m<command-641900871737076>:4\u001B[0m, in \u001B[0;36m____databricks_percent_sql\u001B[0;34m()\u001B[0m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m____databricks_percent_sql\u001B[39m():\n",
       "\u001B[1;32m      3\u001B[0m   \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbase64\u001B[39;00m\n",
       "\u001B[0;32m----> 4\u001B[0m   df \u001B[38;5;241m=\u001B[39m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase64\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstandard_b64decode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mU0VMRUNUIGFub19pbnNjcmljYW8sIENPVU5UKCopIEFTIG51bV9jYWRhc3Ryb3MKRlJPTSBzaWx2ZXIudGVtYXNfYW1iaWVudGFpcwpHUk9VUCBCWSBhbm9faW5zY3JpY2FvCk9SREVSIEJZIGFub19pbnNjcmljYW8=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m      5\u001B[0m   display(df)\n",
       "\u001B[1;32m      6\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/session.py:1387\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1385\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[1;32m   1386\u001B[0m     litArgs \u001B[38;5;241m=\u001B[39m {k: _to_java_column(lit(v)) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m (args \u001B[38;5;129;01mor\u001B[39;00m {})\u001B[38;5;241m.\u001B[39mitems()}\n",
       "\u001B[0;32m-> 1387\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43msqlQuery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlitArgs\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m)\n",
       "\u001B[1;32m   1388\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m   1389\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(kwargs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `silver`.`temas_ambientais` cannot be found. Verify the spelling and correctness of the schema and catalog.\n",
       "If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\n",
       "To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 2 pos 5;\n",
       "'Sort ['ano_inscricao ASC NULLS FIRST], true\n",
       "+- 'Aggregate ['ano_inscricao], ['ano_inscricao, count(1) AS num_cadastros#2929L]\n",
       "   +- 'UnresolvedRelation [silver, temas_ambientais], [], false\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\nFile \u001B[0;32m<command-641900871737076>:7\u001B[0m\n\u001B[1;32m      5\u001B[0m     display(df)\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n\u001B[0;32m----> 7\u001B[0m   _sqldf \u001B[38;5;241m=\u001B[39m \u001B[43m____databricks_percent_sql\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m      9\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m ____databricks_percent_sql\n\nFile \u001B[0;32m<command-641900871737076>:4\u001B[0m, in \u001B[0;36m____databricks_percent_sql\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m____databricks_percent_sql\u001B[39m():\n\u001B[1;32m      3\u001B[0m   \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbase64\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m   df \u001B[38;5;241m=\u001B[39m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase64\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstandard_b64decode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mU0VMRUNUIGFub19pbnNjcmljYW8sIENPVU5UKCopIEFTIG51bV9jYWRhc3Ryb3MKRlJPTSBzaWx2ZXIudGVtYXNfYW1iaWVudGFpcwpHUk9VUCBCWSBhbm9faW5zY3JpY2FvCk9SREVSIEJZIGFub19pbnNjcmljYW8=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m   display(df)\n\u001B[1;32m      6\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m df\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/session.py:1387\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n\u001B[1;32m   1385\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1386\u001B[0m     litArgs \u001B[38;5;241m=\u001B[39m {k: _to_java_column(lit(v)) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m (args \u001B[38;5;129;01mor\u001B[39;00m {})\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[0;32m-> 1387\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43msqlQuery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlitArgs\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m   1388\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m   1389\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(kwargs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\n\u001B[0;31mAnalysisException\u001B[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `silver`.`temas_ambientais` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 2 pos 5;\n'Sort ['ano_inscricao ASC NULLS FIRST], true\n+- 'Aggregate ['ano_inscricao], ['ano_inscricao, count(1) AS num_cadastros#2929L]\n   +- 'UnresolvedRelation [silver, temas_ambientais], [], false\n",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: [TABLE_OR_VIEW_NOT_FOUND] The table or view `silver`.`temas_ambientais` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 2 pos 5;\n'Sort ['ano_inscricao ASC NULLS FIRST], true\n+- 'Aggregate ['ano_inscricao], ['ano_inscricao, count(1) AS num_cadastros#2929L]\n   +- 'UnresolvedRelation [silver, temas_ambientais], [], false\n",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT ano_inscricao, COUNT(*) AS num_cadastros\n",
    "FROM silver.temas_ambientais\n",
    "GROUP BY ano_inscricao\n",
    "ORDER BY ano_inscricao;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb585948-bb14-420f-b024-4df6b3779328",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "4. Calcule o percentual médio de área remanescente de vegetação nativa em comparação à área total da propriedade.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7e1055e-5d65-4557-a791-a4ab6870de49",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-641900871737078>:7\u001B[0m\n",
       "\u001B[1;32m      5\u001B[0m     display(df)\n",
       "\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
       "\u001B[0;32m----> 7\u001B[0m   _sqldf \u001B[38;5;241m=\u001B[39m \u001B[43m____databricks_percent_sql\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m      9\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m ____databricks_percent_sql\n",
       "\n",
       "File \u001B[0;32m<command-641900871737078>:4\u001B[0m, in \u001B[0;36m____databricks_percent_sql\u001B[0;34m()\u001B[0m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m____databricks_percent_sql\u001B[39m():\n",
       "\u001B[1;32m      3\u001B[0m   \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbase64\u001B[39;00m\n",
       "\u001B[0;32m----> 4\u001B[0m   df \u001B[38;5;241m=\u001B[39m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase64\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstandard_b64decode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mU0VMRUNUIEFWRyhhcmVhX3JlbWFuZXNjZW50ZV92ZWdldGFjYW9fbmF0aXZhICAvIGFyZWFfZG9faW1vdmVsKSAqIDEwMCBBUyBwZXJjZW50dWFsX21lZGlvCkZST00gc2lsdmVyLnRlbWFzX2FtYmllbnRhaXM=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m      5\u001B[0m   display(df)\n",
       "\u001B[1;32m      6\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/session.py:1387\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1385\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[1;32m   1386\u001B[0m     litArgs \u001B[38;5;241m=\u001B[39m {k: _to_java_column(lit(v)) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m (args \u001B[38;5;129;01mor\u001B[39;00m {})\u001B[38;5;241m.\u001B[39mitems()}\n",
       "\u001B[0;32m-> 1387\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43msqlQuery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlitArgs\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m)\n",
       "\u001B[1;32m   1388\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m   1389\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(kwargs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `silver`.`temas_ambientais` cannot be found. Verify the spelling and correctness of the schema and catalog.\n",
       "If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\n",
       "To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 2 pos 5;\n",
       "'Project [('AVG(('area_remanescente_vegetacao_nativa / 'area_do_imovel)) * 100) AS percentual_medio#2931]\n",
       "+- 'UnresolvedRelation [silver, temas_ambientais], [], false\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\nFile \u001B[0;32m<command-641900871737078>:7\u001B[0m\n\u001B[1;32m      5\u001B[0m     display(df)\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n\u001B[0;32m----> 7\u001B[0m   _sqldf \u001B[38;5;241m=\u001B[39m \u001B[43m____databricks_percent_sql\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m      9\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m ____databricks_percent_sql\n\nFile \u001B[0;32m<command-641900871737078>:4\u001B[0m, in \u001B[0;36m____databricks_percent_sql\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m____databricks_percent_sql\u001B[39m():\n\u001B[1;32m      3\u001B[0m   \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbase64\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m   df \u001B[38;5;241m=\u001B[39m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase64\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstandard_b64decode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mU0VMRUNUIEFWRyhhcmVhX3JlbWFuZXNjZW50ZV92ZWdldGFjYW9fbmF0aXZhICAvIGFyZWFfZG9faW1vdmVsKSAqIDEwMCBBUyBwZXJjZW50dWFsX21lZGlvCkZST00gc2lsdmVyLnRlbWFzX2FtYmllbnRhaXM=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m   display(df)\n\u001B[1;32m      6\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m df\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/session.py:1387\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n\u001B[1;32m   1385\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1386\u001B[0m     litArgs \u001B[38;5;241m=\u001B[39m {k: _to_java_column(lit(v)) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m (args \u001B[38;5;129;01mor\u001B[39;00m {})\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[0;32m-> 1387\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43msqlQuery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlitArgs\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m   1388\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m   1389\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(kwargs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\n\u001B[0;31mAnalysisException\u001B[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `silver`.`temas_ambientais` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 2 pos 5;\n'Project [('AVG(('area_remanescente_vegetacao_nativa / 'area_do_imovel)) * 100) AS percentual_medio#2931]\n+- 'UnresolvedRelation [silver, temas_ambientais], [], false\n",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: [TABLE_OR_VIEW_NOT_FOUND] The table or view `silver`.`temas_ambientais` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 2 pos 5;\n'Project [('AVG(('area_remanescente_vegetacao_nativa / 'area_do_imovel)) * 100) AS percentual_medio#2931]\n+- 'UnresolvedRelation [silver, temas_ambientais], [], false\n",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT AVG(area_remanescente_vegetacao_nativa  / area_do_imovel) * 100 AS percentual_medio\n",
    "FROM silver.temas_ambientais;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f47cc1f0-c56b-48f5-9883-f4ed2334a47c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "5. Construa uma consulta que mostre a contagem de propriedades rurais por estado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5240d45c-edce-4e4a-b175-b88208ba1670",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-641900871737080>:7\u001B[0m\n",
       "\u001B[1;32m      5\u001B[0m     display(df)\n",
       "\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
       "\u001B[0;32m----> 7\u001B[0m   _sqldf \u001B[38;5;241m=\u001B[39m \u001B[43m____databricks_percent_sql\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m      9\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m ____databricks_percent_sql\n",
       "\n",
       "File \u001B[0;32m<command-641900871737080>:4\u001B[0m, in \u001B[0;36m____databricks_percent_sql\u001B[0;34m()\u001B[0m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m____databricks_percent_sql\u001B[39m():\n",
       "\u001B[1;32m      3\u001B[0m   \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbase64\u001B[39;00m\n",
       "\u001B[0;32m----> 4\u001B[0m   df \u001B[38;5;241m=\u001B[39m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase64\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstandard_b64decode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mU0VMRUNUIHVmLCBjb3VudCAoKikgQVMgbnVtX3Byb3ByaWVkYWRlcwpGUk9NIHNpbHZlci50ZW1hc19hbWJpZW50YWlzCkdST1VQIEJZIHVmCk9SREVSIEJZIG51bV9wcm9wcmllZGFkZXMgREVTQw==\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m      5\u001B[0m   display(df)\n",
       "\u001B[1;32m      6\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/session.py:1387\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1385\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[1;32m   1386\u001B[0m     litArgs \u001B[38;5;241m=\u001B[39m {k: _to_java_column(lit(v)) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m (args \u001B[38;5;129;01mor\u001B[39;00m {})\u001B[38;5;241m.\u001B[39mitems()}\n",
       "\u001B[0;32m-> 1387\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43msqlQuery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlitArgs\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m)\n",
       "\u001B[1;32m   1388\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m   1389\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(kwargs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `silver`.`temas_ambientais` cannot be found. Verify the spelling and correctness of the schema and catalog.\n",
       "If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\n",
       "To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 2 pos 5;\n",
       "'Sort ['num_propriedades DESC NULLS LAST], true\n",
       "+- 'Aggregate ['uf], ['uf, count(1) AS num_propriedades#2932L]\n",
       "   +- 'UnresolvedRelation [silver, temas_ambientais], [], false\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\nFile \u001B[0;32m<command-641900871737080>:7\u001B[0m\n\u001B[1;32m      5\u001B[0m     display(df)\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n\u001B[0;32m----> 7\u001B[0m   _sqldf \u001B[38;5;241m=\u001B[39m \u001B[43m____databricks_percent_sql\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m      9\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m ____databricks_percent_sql\n\nFile \u001B[0;32m<command-641900871737080>:4\u001B[0m, in \u001B[0;36m____databricks_percent_sql\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m____databricks_percent_sql\u001B[39m():\n\u001B[1;32m      3\u001B[0m   \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbase64\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m   df \u001B[38;5;241m=\u001B[39m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase64\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstandard_b64decode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mU0VMRUNUIHVmLCBjb3VudCAoKikgQVMgbnVtX3Byb3ByaWVkYWRlcwpGUk9NIHNpbHZlci50ZW1hc19hbWJpZW50YWlzCkdST1VQIEJZIHVmCk9SREVSIEJZIG51bV9wcm9wcmllZGFkZXMgREVTQw==\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m   display(df)\n\u001B[1;32m      6\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m df\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/session.py:1387\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n\u001B[1;32m   1385\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1386\u001B[0m     litArgs \u001B[38;5;241m=\u001B[39m {k: _to_java_column(lit(v)) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m (args \u001B[38;5;129;01mor\u001B[39;00m {})\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[0;32m-> 1387\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43msqlQuery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlitArgs\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m   1388\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m   1389\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(kwargs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\n\u001B[0;31mAnalysisException\u001B[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `silver`.`temas_ambientais` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 2 pos 5;\n'Sort ['num_propriedades DESC NULLS LAST], true\n+- 'Aggregate ['uf], ['uf, count(1) AS num_propriedades#2932L]\n   +- 'UnresolvedRelation [silver, temas_ambientais], [], false\n",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: [TABLE_OR_VIEW_NOT_FOUND] The table or view `silver`.`temas_ambientais` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 2 pos 5;\n'Sort ['num_propriedades DESC NULLS LAST], true\n+- 'Aggregate ['uf], ['uf, count(1) AS num_propriedades#2932L]\n   +- 'UnresolvedRelation [silver, temas_ambientais], [], false\n",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT uf, count (*) AS num_propriedades\n",
    "FROM silver.temas_ambientais\n",
    "GROUP BY uf\n",
    "ORDER BY num_propriedades DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76af6971-6f79-471c-8ec0-6419171ce984",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "6. Faça a média de área entre todas as propriedades. Calcule quantas propriedades por\n",
    "estado que estão acima da média."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc1a40dc-c78b-485d-839f-2db91354abbd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-641900871737082>:7\u001B[0m\n",
       "\u001B[1;32m      5\u001B[0m     display(df)\n",
       "\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
       "\u001B[0;32m----> 7\u001B[0m   _sqldf \u001B[38;5;241m=\u001B[39m \u001B[43m____databricks_percent_sql\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m      9\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m ____databricks_percent_sql\n",
       "\n",
       "File \u001B[0;32m<command-641900871737082>:4\u001B[0m, in \u001B[0;36m____databricks_percent_sql\u001B[0;34m()\u001B[0m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m____databricks_percent_sql\u001B[39m():\n",
       "\u001B[1;32m      3\u001B[0m   \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbase64\u001B[39;00m\n",
       "\u001B[0;32m----> 4\u001B[0m   df \u001B[38;5;241m=\u001B[39m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase64\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstandard_b64decode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mV0lUSCBtZWRpYV9hcmVhIEFTICgKICBTRUxFQ1QgQVZHKGFyZWFfZG9faW1vdmVsKSBBUyBtZWRpYV9hcmVhCiAgRlJPTSBzaWx2ZXIudGVtYXNfYW1iaWVudGFpcwopClNFTEVDVCAKICB0LnVmLCAKICBDT1VOVCh0LnJlZ2lzdHJvX2NhcikgQVMgbnVtX3Byb3ByaWVkYWRlc19hY2ltYV9tZWRpYQpGUk9NIAogIHNpbHZlci50ZW1hc19hbWJpZW50YWlzIHQKQ1JPU1MgSk9JTiAKICBtZWRpYV9hcmVhCldIRVJFIAogIHQuYXJlYV9kb19pbW92ZWwgPiBtZWRpYV9hcmVhLm1lZGlhX2FyZWEKR1JPVVAgQlkgCiAgdC51ZgpPUkRFUiBCWSBudW1fcHJvcHJpZWRhZGVzX2FjaW1hX21lZGlh\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m      5\u001B[0m   display(df)\n",
       "\u001B[1;32m      6\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/session.py:1387\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1385\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[1;32m   1386\u001B[0m     litArgs \u001B[38;5;241m=\u001B[39m {k: _to_java_column(lit(v)) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m (args \u001B[38;5;129;01mor\u001B[39;00m {})\u001B[38;5;241m.\u001B[39mitems()}\n",
       "\u001B[0;32m-> 1387\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43msqlQuery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlitArgs\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m)\n",
       "\u001B[1;32m   1388\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m   1389\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(kwargs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `silver`.`temas_ambientais` cannot be found. Verify the spelling and correctness of the schema and catalog.\n",
       "If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\n",
       "To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 9 pos 2;\n",
       "'WithCTE\n",
       ":- 'CTERelationDef 0, false\n",
       ":  +- 'SubqueryAlias media_area\n",
       ":     +- 'Project ['AVG('area_do_imovel) AS media_area#2935]\n",
       ":        +- 'UnresolvedRelation [silver, temas_ambientais], [], false\n",
       "+- 'Sort ['num_propriedades_acima_media ASC NULLS FIRST], true\n",
       "   +- 'Aggregate ['t.uf], ['t.uf, 'COUNT('t.registro_car) AS num_propriedades_acima_media#2934]\n",
       "      +- 'Filter ('t.area_do_imovel > 'media_area.media_area)\n",
       "         +- 'Join Cross\n",
       "            :- 'SubqueryAlias t\n",
       "            :  +- 'UnresolvedRelation [silver, temas_ambientais], [], false\n",
       "            +- 'SubqueryAlias media_area\n",
       "               +- 'CTERelationRef 0, false\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\nFile \u001B[0;32m<command-641900871737082>:7\u001B[0m\n\u001B[1;32m      5\u001B[0m     display(df)\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n\u001B[0;32m----> 7\u001B[0m   _sqldf \u001B[38;5;241m=\u001B[39m \u001B[43m____databricks_percent_sql\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m      9\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m ____databricks_percent_sql\n\nFile \u001B[0;32m<command-641900871737082>:4\u001B[0m, in \u001B[0;36m____databricks_percent_sql\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m____databricks_percent_sql\u001B[39m():\n\u001B[1;32m      3\u001B[0m   \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbase64\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m   df \u001B[38;5;241m=\u001B[39m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase64\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstandard_b64decode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mV0lUSCBtZWRpYV9hcmVhIEFTICgKICBTRUxFQ1QgQVZHKGFyZWFfZG9faW1vdmVsKSBBUyBtZWRpYV9hcmVhCiAgRlJPTSBzaWx2ZXIudGVtYXNfYW1iaWVudGFpcwopClNFTEVDVCAKICB0LnVmLCAKICBDT1VOVCh0LnJlZ2lzdHJvX2NhcikgQVMgbnVtX3Byb3ByaWVkYWRlc19hY2ltYV9tZWRpYQpGUk9NIAogIHNpbHZlci50ZW1hc19hbWJpZW50YWlzIHQKQ1JPU1MgSk9JTiAKICBtZWRpYV9hcmVhCldIRVJFIAogIHQuYXJlYV9kb19pbW92ZWwgPiBtZWRpYV9hcmVhLm1lZGlhX2FyZWEKR1JPVVAgQlkgCiAgdC51ZgpPUkRFUiBCWSBudW1fcHJvcHJpZWRhZGVzX2FjaW1hX21lZGlh\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m   display(df)\n\u001B[1;32m      6\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m df\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/session.py:1387\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n\u001B[1;32m   1385\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1386\u001B[0m     litArgs \u001B[38;5;241m=\u001B[39m {k: _to_java_column(lit(v)) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m (args \u001B[38;5;129;01mor\u001B[39;00m {})\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[0;32m-> 1387\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43msqlQuery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlitArgs\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m   1388\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m   1389\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(kwargs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\n\u001B[0;31mAnalysisException\u001B[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `silver`.`temas_ambientais` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 9 pos 2;\n'WithCTE\n:- 'CTERelationDef 0, false\n:  +- 'SubqueryAlias media_area\n:     +- 'Project ['AVG('area_do_imovel) AS media_area#2935]\n:        +- 'UnresolvedRelation [silver, temas_ambientais], [], false\n+- 'Sort ['num_propriedades_acima_media ASC NULLS FIRST], true\n   +- 'Aggregate ['t.uf], ['t.uf, 'COUNT('t.registro_car) AS num_propriedades_acima_media#2934]\n      +- 'Filter ('t.area_do_imovel > 'media_area.media_area)\n         +- 'Join Cross\n            :- 'SubqueryAlias t\n            :  +- 'UnresolvedRelation [silver, temas_ambientais], [], false\n            +- 'SubqueryAlias media_area\n               +- 'CTERelationRef 0, false\n",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: [TABLE_OR_VIEW_NOT_FOUND] The table or view `silver`.`temas_ambientais` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 9 pos 2;\n'WithCTE\n:- 'CTERelationDef 0, false\n:  +- 'SubqueryAlias media_area\n:     +- 'Project ['AVG('area_do_imovel) AS media_area#2935]\n:        +- 'UnresolvedRelation [silver, temas_ambientais], [], false\n+- 'Sort ['num_propriedades_acima_media ASC NULLS FIRST], true\n   +- 'Aggregate ['t.uf], ['t.uf, 'COUNT('t.registro_car) AS num_propriedades_acima_media#2934]\n      +- 'Filter ('t.area_do_imovel > 'media_area.media_area)\n         +- 'Join Cross\n            :- 'SubqueryAlias t\n            :  +- 'UnresolvedRelation [silver, temas_ambientais], [], false\n            +- 'SubqueryAlias media_area\n               +- 'CTERelationRef 0, false\n",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "WITH media_area AS (\n",
    "  SELECT AVG(area_do_imovel) AS media_area\n",
    "  FROM silver.temas_ambientais\n",
    ")\n",
    "SELECT \n",
    "  t.uf, \n",
    "  COUNT(t.registro_car) AS num_propriedades_acima_media\n",
    "FROM \n",
    "  silver.temas_ambientais t\n",
    "CROSS JOIN \n",
    "  media_area\n",
    "WHERE \n",
    "  t.area_do_imovel > media_area.media_area\n",
    "GROUP BY \n",
    "  t.uf\n",
    "ORDER BY num_propriedades_acima_media;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68413750-f68d-4bf0-b4b9-5a8cbe79602b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "7.  Comparar o número de propriedades com área remanescente de vegetação nativa com o número total de propriedades por UF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b752574c-2889-401a-8aa4-467535460818",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-641900871737086>:7\u001B[0m\n",
       "\u001B[1;32m      5\u001B[0m     display(df)\n",
       "\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
       "\u001B[0;32m----> 7\u001B[0m   _sqldf \u001B[38;5;241m=\u001B[39m \u001B[43m____databricks_percent_sql\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m      9\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m ____databricks_percent_sql\n",
       "\n",
       "File \u001B[0;32m<command-641900871737086>:4\u001B[0m, in \u001B[0;36m____databricks_percent_sql\u001B[0;34m()\u001B[0m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m____databricks_percent_sql\u001B[39m():\n",
       "\u001B[1;32m      3\u001B[0m   \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbase64\u001B[39;00m\n",
       "\u001B[0;32m----> 4\u001B[0m   df \u001B[38;5;241m=\u001B[39m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase64\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstandard_b64decode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mU0VMRUNUIHBuLnVmLAogICAgICAgcG4ubnVtX3Byb3ByaWVkYWRlc19hcmVhX25hdGl2YSBBUyBudW1fYXJlYV9uYXRpdmEsCiAgICAgICBDT1VOVCh0LnJlZ2lzdHJvX2NhcikgQVMgbnVtX3RvdGFsX3Byb3ByaWVkYWRlcywKICAgICAgIChudW1fYXJlYV9uYXRpdmEgLyBudW1fdG90YWxfcHJvcHJpZWRhZGVzKSAqIDEwMCBBUyBwb3JjZW50YWdlbV9hcmVhX25hdGl2YQpGUk9NIGdvbGQucHJvcHJpZWRhZGVzX2FyZWFfbmF0aXZhX3VmIHBuCkpPSU4gc2lsdmVyLnRlbWFzX2FtYmllbnRhaXMgdApPTiBwbi51ZiA9IHQudWYKR1JPVVAgQlkgcG4udWYsIHBuLm51bV9wcm9wcmllZGFkZXNfYXJlYV9uYXRpdmEKT1JERVIgQlkgcG4ubnVtX3Byb3ByaWVkYWRlc19hcmVhX25hdGl2YSBERVND\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m      5\u001B[0m   display(df)\n",
       "\u001B[1;32m      6\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/session.py:1387\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1385\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[1;32m   1386\u001B[0m     litArgs \u001B[38;5;241m=\u001B[39m {k: _to_java_column(lit(v)) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m (args \u001B[38;5;129;01mor\u001B[39;00m {})\u001B[38;5;241m.\u001B[39mitems()}\n",
       "\u001B[0;32m-> 1387\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43msqlQuery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlitArgs\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m)\n",
       "\u001B[1;32m   1388\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m   1389\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(kwargs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `gold`.`propriedades_area_nativa_uf` cannot be found. Verify the spelling and correctness of the schema and catalog.\n",
       "If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\n",
       "To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 5 pos 5;\n",
       "'Sort ['pn.num_propriedades_area_nativa DESC NULLS LAST], true\n",
       "+- 'Aggregate ['pn.uf, 'pn.num_propriedades_area_nativa], ['pn.uf, 'pn.num_propriedades_area_nativa AS num_area_nativa#2938, 'COUNT('t.registro_car) AS num_total_propriedades#2939, (('num_area_nativa / 'num_total_propriedades) * 100) AS porcentagem_area_nativa#2940]\n",
       "   +- 'Join Inner, ('pn.uf = 't.uf)\n",
       "      :- 'SubqueryAlias pn\n",
       "      :  +- 'UnresolvedRelation [gold, propriedades_area_nativa_uf], [], false\n",
       "      +- 'SubqueryAlias t\n",
       "         +- 'UnresolvedRelation [silver, temas_ambientais], [], false\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\nFile \u001B[0;32m<command-641900871737086>:7\u001B[0m\n\u001B[1;32m      5\u001B[0m     display(df)\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n\u001B[0;32m----> 7\u001B[0m   _sqldf \u001B[38;5;241m=\u001B[39m \u001B[43m____databricks_percent_sql\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m      9\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m ____databricks_percent_sql\n\nFile \u001B[0;32m<command-641900871737086>:4\u001B[0m, in \u001B[0;36m____databricks_percent_sql\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m____databricks_percent_sql\u001B[39m():\n\u001B[1;32m      3\u001B[0m   \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mbase64\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m   df \u001B[38;5;241m=\u001B[39m \u001B[43mspark\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase64\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstandard_b64decode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mU0VMRUNUIHBuLnVmLAogICAgICAgcG4ubnVtX3Byb3ByaWVkYWRlc19hcmVhX25hdGl2YSBBUyBudW1fYXJlYV9uYXRpdmEsCiAgICAgICBDT1VOVCh0LnJlZ2lzdHJvX2NhcikgQVMgbnVtX3RvdGFsX3Byb3ByaWVkYWRlcywKICAgICAgIChudW1fYXJlYV9uYXRpdmEgLyBudW1fdG90YWxfcHJvcHJpZWRhZGVzKSAqIDEwMCBBUyBwb3JjZW50YWdlbV9hcmVhX25hdGl2YQpGUk9NIGdvbGQucHJvcHJpZWRhZGVzX2FyZWFfbmF0aXZhX3VmIHBuCkpPSU4gc2lsdmVyLnRlbWFzX2FtYmllbnRhaXMgdApPTiBwbi51ZiA9IHQudWYKR1JPVVAgQlkgcG4udWYsIHBuLm51bV9wcm9wcmllZGFkZXNfYXJlYV9uYXRpdmEKT1JERVIgQlkgcG4ubnVtX3Byb3ByaWVkYWRlc19hcmVhX25hdGl2YSBERVND\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m   display(df)\n\u001B[1;32m      6\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m df\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/session.py:1387\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n\u001B[1;32m   1385\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1386\u001B[0m     litArgs \u001B[38;5;241m=\u001B[39m {k: _to_java_column(lit(v)) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m (args \u001B[38;5;129;01mor\u001B[39;00m {})\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[0;32m-> 1387\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m(\u001B[49m\u001B[43msqlQuery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlitArgs\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m   1388\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m   1389\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(kwargs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\n\u001B[0;31mAnalysisException\u001B[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `gold`.`propriedades_area_nativa_uf` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 5 pos 5;\n'Sort ['pn.num_propriedades_area_nativa DESC NULLS LAST], true\n+- 'Aggregate ['pn.uf, 'pn.num_propriedades_area_nativa], ['pn.uf, 'pn.num_propriedades_area_nativa AS num_area_nativa#2938, 'COUNT('t.registro_car) AS num_total_propriedades#2939, (('num_area_nativa / 'num_total_propriedades) * 100) AS porcentagem_area_nativa#2940]\n   +- 'Join Inner, ('pn.uf = 't.uf)\n      :- 'SubqueryAlias pn\n      :  +- 'UnresolvedRelation [gold, propriedades_area_nativa_uf], [], false\n      +- 'SubqueryAlias t\n         +- 'UnresolvedRelation [silver, temas_ambientais], [], false\n",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: [TABLE_OR_VIEW_NOT_FOUND] The table or view `gold`.`propriedades_area_nativa_uf` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 5 pos 5;\n'Sort ['pn.num_propriedades_area_nativa DESC NULLS LAST], true\n+- 'Aggregate ['pn.uf, 'pn.num_propriedades_area_nativa], ['pn.uf, 'pn.num_propriedades_area_nativa AS num_area_nativa#2938, 'COUNT('t.registro_car) AS num_total_propriedades#2939, (('num_area_nativa / 'num_total_propriedades) * 100) AS porcentagem_area_nativa#2940]\n   +- 'Join Inner, ('pn.uf = 't.uf)\n      :- 'SubqueryAlias pn\n      :  +- 'UnresolvedRelation [gold, propriedades_area_nativa_uf], [], false\n      +- 'SubqueryAlias t\n         +- 'UnresolvedRelation [silver, temas_ambientais], [], false\n",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT pn.uf,\n",
    "       pn.num_propriedades_area_nativa AS num_area_nativa,\n",
    "       COUNT(t.registro_car) AS num_total_propriedades,\n",
    "       (num_area_nativa / num_total_propriedades) * 100 AS porcentagem_area_nativa\n",
    "FROM gold.propriedades_area_nativa_uf pn\n",
    "JOIN silver.temas_ambientais t\n",
    "ON pn.uf = t.uf\n",
    "GROUP BY pn.uf, pn.num_propriedades_area_nativa\n",
    "ORDER BY pn.num_propriedades_area_nativa DESC;\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2597619522200205,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Projeto Big Data - Cadastro Ambiental Rural",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
